{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T14:56:45.596378Z",
     "start_time": "2019-01-09T14:56:43.983804Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T14:56:46.157152Z",
     "start_time": "2019-01-09T14:56:45.600202Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data: (5078, 9000, 1)\n",
      "Train Label:  (5078, 4)\n",
      "Vali Data:  (2032, 9000, 1)\n",
      "Vali Label:  (2032, 4)\n",
      "Test Data:  (3041, 9000, 1)\n",
      "Test Label:  (3041, 4)\n"
     ]
    }
   ],
   "source": [
    "trainD = np.load(\"/home/hsiehch/30s/train_data.npy\")\n",
    "trainL = np.load(\"/home/hsiehch/30s/train_label.npy\")\n",
    "validationD = np.load(\"/home/hsiehch/30s/validation_data.npy\")\n",
    "validationL = np.load(\"/home/hsiehch/30s/validation_label.npy\")\n",
    "testD = np.load(\"/home/hsiehch/30s/test_data.npy\")\n",
    "testL = np.load(\"/home/hsiehch/30s/test_label.npy\")\n",
    "\n",
    "trainData = trainD.reshape((trainD.shape[0], trainD.shape[1], 1))\n",
    "trainLabel = np_utils.to_categorical(trainL, 4)\n",
    "validationData = validationD.reshape((validationD.shape[0], validationD.shape[1], 1))\n",
    "validationLabel = np_utils.to_categorical(validationL, 4)\n",
    "testData = testD.reshape((testD.shape[0], testD.shape[1], 1))\n",
    "testLabel = np_utils.to_categorical(testL, 4)\n",
    "\n",
    "print('Train Data:', trainData.shape)\n",
    "print('Train Label: ', trainLabel.shape)\n",
    "print('Vali Data: ', validationData.shape)\n",
    "print('Vali Label: ', validationLabel.shape)\n",
    "print('Test Data: ', testData.shape)\n",
    "print('Test Label: ', testLabel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T14:56:47.154040Z",
     "start_time": "2019-01-09T14:56:46.159921Z"
    }
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    inputs = tf.placeholder(tf.float32, shape=(None, 9000, 1), name='inputs')\n",
    "    labels = tf.placeholder(tf.float32, shape=(None, 4), name='labels')    \n",
    "\n",
    "    conv1 = tf.layers.conv1d(inputs, filters=32, kernel_size=7, padding='valid', activation=tf.nn.relu)\n",
    "    max_pool_1 = tf.layers.max_pooling1d(conv1, pool_size=2, strides=2)\n",
    "    \n",
    "    conv2 = tf.layers.conv1d(max_pool_1, filters=32, kernel_size=7, padding='valid', activation=tf.nn.relu)\n",
    "    max_pool_2 = tf.layers.max_pooling1d(conv2, pool_size=2, strides=2)\n",
    "    \n",
    "    conv3 = tf.layers.conv1d(max_pool_2, filters=64, kernel_size=7, padding='valid', activation=tf.nn.relu)\n",
    "    max_pool_3 = tf.layers.max_pooling1d(conv3, pool_size=2, strides=2)\n",
    "    \n",
    "    conv4 = tf.layers.conv1d(max_pool_3, filters=64, kernel_size=3, padding='valid', activation=tf.nn.relu)\n",
    "    max_pool_4 = tf.layers.max_pooling1d(conv4, pool_size=2, strides=2)\n",
    "    \n",
    "    conv5 = tf.layers.conv1d(max_pool_4, filters=128, kernel_size=3, padding='valid', activation=tf.nn.relu)\n",
    "    max_pool_5 = tf.layers.max_pooling1d(conv5, pool_size=2, strides=2)\n",
    "    \n",
    "    conv6 = tf.layers.conv1d(max_pool_5, filters=128, kernel_size=3, padding='valid', activation=tf.nn.relu)\n",
    "    max_pool_6 = tf.layers.max_pooling1d(conv6, pool_size=2, strides=2)\n",
    "    dropout_1 = tf.layers.dropout(max_pool_6, rate=0.5)\n",
    "    \n",
    "    conv7 = tf.layers.conv1d(dropout_1, filters=256, kernel_size=3, padding='valid', activation=tf.nn.relu)\n",
    "    max_pool_7 = tf.layers.max_pooling1d(conv7, pool_size=2, strides=2)\n",
    "    \n",
    "    conv8 = tf.layers.conv1d(max_pool_7, filters=256, kernel_size=3, padding='valid', activation=tf.nn.relu)\n",
    "    max_pool_8 = tf.layers.max_pooling1d(conv8, pool_size=2, strides=2)\n",
    "    dropout_2 = tf.layers.dropout(max_pool_8, rate=0.5)\n",
    "    \n",
    "    conv9 = tf.layers.conv1d(dropout_2, filters=512, kernel_size=3, padding='valid', activation=tf.nn.relu)\n",
    "    max_pool_9 = tf.layers.max_pooling1d(conv9, pool_size=2, strides=2)\n",
    "    dropout_3 = tf.layers.dropout(max_pool_9, rate=0.5)\n",
    "    \n",
    "    conv10 = tf.layers.conv1d(dropout_3, filters=512, kernel_size=3, padding='valid', activation=tf.nn.relu)\n",
    "    max_pool_10 = tf.layers.max_pooling1d(conv10, pool_size=2, strides=2)\n",
    "    \n",
    "    conv11 = tf.layers.conv1d(max_pool_10, filters=512, kernel_size=3, padding='valid', activation=tf.nn.relu)\n",
    "    \n",
    "\n",
    "    \n",
    "    flatten = tf.layers.flatten(conv11)\n",
    "    dense_1 = tf.layers.dense(flatten, 128, activation=tf.nn.relu)\n",
    "    dropout_4 = tf.layers.dropout(dense_1, rate=0.5)\n",
    "    dense_2 = tf.layers.dense(dropout_4, 32, activation=tf.nn.relu)\n",
    "    output = tf.layers.dense(dense_2, 4)\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=output, labels=labels))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)\n",
    " \n",
    "    # Accuracy\n",
    "    correct_pred = tf.equal(tf.argmax(output, 1), tf.argmax(labels, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T14:56:47.174097Z",
     "start_time": "2019-01-09T14:56:47.156426Z"
    }
   },
   "outputs": [],
   "source": [
    "iteration = 100\n",
    "batch_size = 70\n",
    "# batch_index = []\n",
    "# Make batch index\n",
    "train_length = trainData.shape[0]\n",
    "start = 0\n",
    "end = batch_size\n",
    "\n",
    "def batch_generation(data_length):\n",
    "    row = data_length//batch_size\n",
    "    col = batch_size\n",
    "    arr = np.arange(row*col).reshape((row, col))\n",
    "    np.random.shuffle(arr)\n",
    "    return arr\n",
    "\n",
    "# while True:    \n",
    "#     if end + batch_size > train_length:\n",
    "#         batch_index.append([start, train_length])\n",
    "#         break\n",
    "#     else:\n",
    "#         batch_index.append([start, end])\n",
    "#         start = end\n",
    "#         end = end + batch_size\n",
    "\n",
    "# del start, end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T15:02:28.683566Z",
     "start_time": "2019-01-09T14:56:47.176997Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100\n",
      "loss: 00.352600 - acc: 1.0 - val_loss: 01.008896 - val_acc: 0.5866142\n",
      "Epoch: 2/100\n",
      "loss: 00.603331 - acc: 1.0 - val_loss: 00.995078 - val_acc: 0.5866142\n",
      "Epoch: 3/100\n",
      "loss: 00.589230 - acc: 1.0 - val_loss: 00.994599 - val_acc: 0.5866142\n",
      "Epoch: 4/100\n",
      "loss: 00.611545 - acc: 1.0 - val_loss: 00.995987 - val_acc: 0.5866142\n",
      "Epoch: 5/100\n",
      "loss: 00.628307 - acc: 1.0 - val_loss: 00.997708 - val_acc: 0.5866142\n",
      "Epoch: 6/100\n",
      "loss: 00.641782 - acc: 1.0 - val_loss: 00.999627 - val_acc: 0.5866142\n",
      "Epoch: 7/100\n",
      "loss: 00.645154 - acc: 1.0 - val_loss: 01.000419 - val_acc: 0.5866142\n",
      "Epoch: 8/100\n",
      "loss: 00.608382 - acc: 1.0 - val_loss: 00.996233 - val_acc: 0.5866142\n",
      "Epoch: 9/100\n",
      "loss: 00.628072 - acc: 1.0 - val_loss: 00.998236 - val_acc: 0.5866142\n",
      "Epoch: 10/100\n",
      "loss: 00.581340 - acc: 1.0 - val_loss: 00.994523 - val_acc: 0.5866142\n",
      "Epoch: 11/100\n",
      "loss: 00.634050 - acc: 1.0 - val_loss: 00.999104 - val_acc: 0.5866142\n",
      "Epoch: 12/100\n",
      "loss: 00.652482 - acc: 1.0 - val_loss: 01.002319 - val_acc: 0.5866142\n",
      "Epoch: 13/100\n",
      "loss: 00.652684 - acc: 1.0 - val_loss: 01.002354 - val_acc: 0.5866142\n",
      "Epoch: 14/100\n",
      "loss: 00.649961 - acc: 1.0 - val_loss: 01.002161 - val_acc: 0.5866142\n",
      "Epoch: 15/100\n",
      "loss: 00.647209 - acc: 1.0 - val_loss: 01.001815 - val_acc: 0.5866142\n",
      "Epoch: 16/100\n",
      "loss: 00.644955 - acc: 1.0 - val_loss: 01.001543 - val_acc: 0.5866142\n",
      "Epoch: 17/100\n",
      "loss: 00.642890 - acc: 1.0 - val_loss: 01.001296 - val_acc: 0.5866142\n",
      "Epoch: 18/100\n",
      "loss: 00.640905 - acc: 1.0 - val_loss: 01.001057 - val_acc: 0.5866142\n",
      "Epoch: 19/100\n",
      "loss: 00.638963 - acc: 1.0 - val_loss: 01.000822 - val_acc: 0.5866142\n",
      "Epoch: 20/100\n",
      "loss: 00.636976 - acc: 1.0 - val_loss: 01.000576 - val_acc: 0.5866142\n",
      "Epoch: 21/100\n",
      "loss: 00.634737 - acc: 1.0 - val_loss: 01.000309 - val_acc: 0.5866142\n",
      "Epoch: 22/100\n",
      "loss: 00.637014 - acc: 1.0 - val_loss: 01.000234 - val_acc: 0.5866142\n",
      "Epoch: 23/100\n",
      "loss: 00.633801 - acc: 1.0 - val_loss: 01.000029 - val_acc: 0.5866142\n",
      "Epoch: 24/100\n",
      "loss: 00.629915 - acc: 1.0 - val_loss: 00.999505 - val_acc: 0.5866142\n",
      "Epoch: 25/100\n",
      "loss: 00.628284 - acc: 1.0 - val_loss: 00.999294 - val_acc: 0.5866142\n",
      "Epoch: 26/100\n",
      "loss: 00.627384 - acc: 1.0 - val_loss: 00.999260 - val_acc: 0.5866142\n",
      "Epoch: 27/100\n",
      "loss: 00.624584 - acc: 1.0 - val_loss: 00.998885 - val_acc: 0.5866142\n",
      "Epoch: 28/100\n",
      "loss: 00.621716 - acc: 1.0 - val_loss: 00.998468 - val_acc: 0.5866142\n",
      "Epoch: 29/100\n",
      "loss: 00.620474 - acc: 1.0 - val_loss: 00.998383 - val_acc: 0.5866142\n",
      "Epoch: 30/100\n",
      "loss: 00.618317 - acc: 1.0 - val_loss: 00.998110 - val_acc: 0.5866142\n",
      "Epoch: 31/100\n",
      "loss: 00.610173 - acc: 1.0 - val_loss: 00.997061 - val_acc: 0.5866142\n",
      "Epoch: 32/100\n",
      "loss: 00.594732 - acc: 1.0 - val_loss: 00.995246 - val_acc: 0.5866142\n",
      "Epoch: 33/100\n",
      "loss: 00.616665 - acc: 1.0 - val_loss: 00.998005 - val_acc: 0.5866142\n",
      "Epoch: 34/100\n",
      "loss: 00.613036 - acc: 1.0 - val_loss: 00.997522 - val_acc: 0.5866142\n",
      "Epoch: 35/100\n",
      "loss: 00.609713 - acc: 1.0 - val_loss: 00.997070 - val_acc: 0.5866142\n",
      "Epoch: 36/100\n",
      "loss: 00.608145 - acc: 1.0 - val_loss: 00.996886 - val_acc: 0.5866142\n",
      "Epoch: 37/100\n",
      "loss: 00.605542 - acc: 1.0 - val_loss: 00.996569 - val_acc: 0.5866142\n",
      "Epoch: 38/100\n",
      "loss: 00.602880 - acc: 1.0 - val_loss: 00.996259 - val_acc: 0.5866142\n",
      "Epoch: 39/100\n",
      "loss: 00.601812 - acc: 1.0 - val_loss: 00.996150 - val_acc: 0.5866142\n",
      "Epoch: 40/100\n",
      "loss: 00.591928 - acc: 1.0 - val_loss: 00.995051 - val_acc: 0.5866142\n",
      "Epoch: 41/100\n",
      "loss: 00.608578 - acc: 1.0 - val_loss: 00.996858 - val_acc: 0.5866142\n",
      "Epoch: 42/100\n",
      "loss: 00.598848 - acc: 1.0 - val_loss: 00.995775 - val_acc: 0.5866142\n",
      "Epoch: 43/100\n",
      "loss: 00.598109 - acc: 1.0 - val_loss: 00.995747 - val_acc: 0.5866142\n",
      "Epoch: 44/100\n",
      "loss: 00.595799 - acc: 1.0 - val_loss: 00.995503 - val_acc: 0.5866142\n",
      "Epoch: 45/100\n",
      "loss: 00.594433 - acc: 1.0 - val_loss: 00.995366 - val_acc: 0.5866142\n",
      "Epoch: 46/100\n",
      "loss: 00.591159 - acc: 1.0 - val_loss: 00.995032 - val_acc: 0.5866142\n",
      "Epoch: 47/100\n",
      "loss: 00.593559 - acc: 1.0 - val_loss: 00.995295 - val_acc: 0.5866142\n",
      "Epoch: 48/100\n",
      "loss: 00.591500 - acc: 1.0 - val_loss: 00.995091 - val_acc: 0.5866142\n",
      "Epoch: 49/100\n",
      "loss: 00.591005 - acc: 1.0 - val_loss: 00.995043 - val_acc: 0.5866142\n",
      "Epoch: 50/100\n",
      "loss: 00.590233 - acc: 1.0 - val_loss: 00.994972 - val_acc: 0.5866142\n",
      "Epoch: 51/100\n",
      "loss: 00.589538 - acc: 1.0 - val_loss: 00.994910 - val_acc: 0.5866142\n",
      "Epoch: 52/100\n",
      "loss: 00.588906 - acc: 1.0 - val_loss: 00.994854 - val_acc: 0.5866142\n",
      "Epoch: 53/100\n",
      "loss: 00.588292 - acc: 1.0 - val_loss: 00.994801 - val_acc: 0.5866142\n",
      "Epoch: 54/100\n",
      "loss: 00.587724 - acc: 1.0 - val_loss: 00.994753 - val_acc: 0.5866142\n",
      "Epoch: 55/100\n",
      "loss: 00.587121 - acc: 1.0 - val_loss: 00.994703 - val_acc: 0.5866142\n",
      "Epoch: 56/100\n",
      "loss: 00.586522 - acc: 1.0 - val_loss: 00.994655 - val_acc: 0.5866142\n",
      "Epoch: 57/100\n",
      "loss: 00.586163 - acc: 1.0 - val_loss: 00.994622 - val_acc: 0.5866142\n",
      "Epoch: 58/100\n",
      "loss: 00.584483 - acc: 1.0 - val_loss: 00.994475 - val_acc: 0.5866142\n",
      "Epoch: 59/100\n",
      "loss: 00.585829 - acc: 1.0 - val_loss: 00.994560 - val_acc: 0.5866142\n",
      "Epoch: 60/100\n",
      "loss: 00.587182 - acc: 1.0 - val_loss: 00.994730 - val_acc: 0.5866142\n",
      "Epoch: 61/100\n",
      "loss: 00.585592 - acc: 1.0 - val_loss: 00.994587 - val_acc: 0.5866142\n",
      "Epoch: 62/100\n",
      "loss: 00.584726 - acc: 1.0 - val_loss: 00.994514 - val_acc: 0.5866142\n",
      "Epoch: 63/100\n",
      "loss: 00.584100 - acc: 1.0 - val_loss: 00.994462 - val_acc: 0.5866142\n",
      "Epoch: 64/100\n",
      "loss: 00.583575 - acc: 1.0 - val_loss: 00.994420 - val_acc: 0.5866142\n",
      "Epoch: 65/100\n",
      "loss: 00.583100 - acc: 1.0 - val_loss: 00.994382 - val_acc: 0.5866142\n",
      "Epoch: 66/100\n",
      "loss: 00.582674 - acc: 1.0 - val_loss: 00.994349 - val_acc: 0.5866142\n",
      "Epoch: 67/100\n",
      "loss: 00.583214 - acc: 1.0 - val_loss: 00.994316 - val_acc: 0.5866142\n",
      "Epoch: 68/100\n",
      "loss: 00.584101 - acc: 1.0 - val_loss: 00.994464 - val_acc: 0.5866142\n",
      "Epoch: 69/100\n",
      "loss: 00.600917 - acc: 1.0 - val_loss: 00.995862 - val_acc: 0.5866142\n",
      "Epoch: 70/100\n",
      "loss: 00.585176 - acc: 1.0 - val_loss: 00.994474 - val_acc: 0.5866142\n",
      "Epoch: 71/100\n",
      "loss: 00.582386 - acc: 1.0 - val_loss: 00.994307 - val_acc: 0.5866142\n",
      "Epoch: 72/100\n",
      "loss: 00.581360 - acc: 1.0 - val_loss: 00.994244 - val_acc: 0.5866142\n",
      "Epoch: 73/100\n",
      "loss: 00.580743 - acc: 1.0 - val_loss: 00.994201 - val_acc: 0.5866142\n",
      "Epoch: 74/100\n",
      "loss: 00.580283 - acc: 1.0 - val_loss: 00.994168 - val_acc: 0.5866142\n",
      "Epoch: 75/100\n",
      "loss: 00.579890 - acc: 1.0 - val_loss: 00.994140 - val_acc: 0.5866142\n",
      "Epoch: 76/100\n",
      "loss: 00.579533 - acc: 1.0 - val_loss: 00.994114 - val_acc: 0.5866142\n",
      "Epoch: 77/100\n",
      "loss: 00.579201 - acc: 1.0 - val_loss: 00.994091 - val_acc: 0.5866142\n",
      "Epoch: 78/100\n",
      "loss: 00.578888 - acc: 1.0 - val_loss: 00.994069 - val_acc: 0.5866142\n",
      "Epoch: 79/100\n",
      "loss: 00.578570 - acc: 1.0 - val_loss: 00.994047 - val_acc: 0.5866142\n",
      "Epoch: 80/100\n",
      "loss: 00.578449 - acc: 1.0 - val_loss: 00.994036 - val_acc: 0.5866142\n",
      "Epoch: 81/100\n",
      "loss: 00.578062 - acc: 1.0 - val_loss: 00.994012 - val_acc: 0.5866142\n",
      "Epoch: 82/100\n",
      "loss: 00.577770 - acc: 1.0 - val_loss: 00.993992 - val_acc: 0.5866142\n",
      "Epoch: 83/100\n",
      "loss: 00.577895 - acc: 1.0 - val_loss: 00.994009 - val_acc: 0.5866142\n",
      "Epoch: 84/100\n",
      "loss: 00.577947 - acc: 1.0 - val_loss: 00.994016 - val_acc: 0.5866142\n",
      "Epoch: 85/100\n",
      "loss: 00.577208 - acc: 1.0 - val_loss: 00.993957 - val_acc: 0.5866142\n",
      "Epoch: 86/100\n",
      "loss: 00.576841 - acc: 1.0 - val_loss: 00.993931 - val_acc: 0.5866142\n",
      "Epoch: 87/100\n",
      "loss: 00.576573 - acc: 1.0 - val_loss: 00.993914 - val_acc: 0.5866142\n",
      "Epoch: 88/100\n",
      "loss: 00.576336 - acc: 1.0 - val_loss: 00.993898 - val_acc: 0.5866142\n",
      "Epoch: 89/100\n",
      "loss: 00.576106 - acc: 1.0 - val_loss: 00.993883 - val_acc: 0.5866142\n",
      "Epoch: 90/100\n",
      "loss: 00.575893 - acc: 1.0 - val_loss: 00.993870 - val_acc: 0.5866142\n",
      "Epoch: 91/100\n",
      "loss: 00.576389 - acc: 1.0 - val_loss: 00.993914 - val_acc: 0.5866142\n",
      "Epoch: 92/100\n",
      "loss: 00.575676 - acc: 1.0 - val_loss: 00.993861 - val_acc: 0.5866142\n",
      "Epoch: 93/100\n",
      "loss: 00.575318 - acc: 1.0 - val_loss: 00.993835 - val_acc: 0.5866142\n",
      "Epoch: 94/100\n",
      "loss: 00.575071 - acc: 1.0 - val_loss: 00.993819 - val_acc: 0.5866142\n",
      "Epoch: 95/100\n",
      "loss: 00.574858 - acc: 1.0 - val_loss: 00.993805 - val_acc: 0.5866142\n",
      "Epoch: 96/100\n",
      "loss: 00.574658 - acc: 1.0 - val_loss: 00.993792 - val_acc: 0.5866142\n",
      "Epoch: 97/100\n",
      "loss: 00.574466 - acc: 1.0 - val_loss: 00.993781 - val_acc: 0.5866142\n",
      "Epoch: 98/100\n",
      "loss: 00.574274 - acc: 1.0 - val_loss: 00.993769 - val_acc: 0.5866142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 99/100\n",
      "loss: 00.574091 - acc: 1.0 - val_loss: 00.993757 - val_acc: 0.5866142\n",
      "Epoch: 100/100\n",
      "loss: 00.573908 - acc: 1.0 - val_loss: 00.993747 - val_acc: 0.5866142\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    batch_index = batch_generation(trainData.shape[0])\n",
    "    for epoch in range(iteration):\n",
    "        for index in batch_index:\n",
    "            loss, opt, acc = sess.run([cost, optimizer, accuracy],\n",
    "                             feed_dict={inputs: trainData[index],\n",
    "                                        labels: trainLabel[index]\n",
    "                                    })\n",
    "            \n",
    "        val_loss, val_acc = sess.run([cost, accuracy],\n",
    "                             feed_dict={inputs: validationData,\n",
    "                                        labels: validationLabel\n",
    "                                    })\n",
    "        \n",
    "        print(\"Epoch: {}/{}\".format(epoch+1, iteration))\n",
    "        print(\"loss:\", \"{:09f}\".format(loss), \"-\", \"acc:\", acc, \"-\",\n",
    "              \"val_loss:\", \"{:09f}\".format(val_loss), \"-\", \"val_acc:\", val_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
