{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-14T09:15:53.643262Z",
     "start_time": "2018-10-14T09:15:43.108003Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model1 = load_model('noise_nonNoise.h5')\n",
    "\n",
    "model2 = load_model('AON.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-14T09:15:53.832946Z",
     "start_time": "2018-10-14T09:15:53.647016Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3041, 9000, 1)\n",
      "(3041, 4)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv1D, MaxPooling1D, AveragePooling1D, Dropout\n",
    "from keras.layers import BatchNormalization, Activation\n",
    "from keras.initializers import VarianceScaling\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils, multi_gpu_model\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import TensorBoard, EarlyStopping\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "testD = np.load(\"/home/hsiehch/30s/test_data.npy\")\n",
    "testL = np.load(\"/home/hsiehch/30s/test_label.npy\")\n",
    "\n",
    "testData = testD.reshape((testD.shape[0], testD.shape[1], 1))\n",
    "testLabel = np_utils.to_categorical(testL, 4)\n",
    "\n",
    "print(testData.shape)\n",
    "print(testLabel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-14T09:16:21.750780Z",
     "start_time": "2018-10-14T09:15:53.835043Z"
    }
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for i in testData:\n",
    "    # 0: Non-noise 1: Noise\n",
    "    i = i.reshape((1, testData.shape[1], 1))\n",
    "    noise_or_nonNoise = model1.predict_classes(i, batch_size=1)\n",
    "    \n",
    "    if noise_or_nonNoise == 1:\n",
    "        results.append(1)\n",
    "    else:\n",
    "        AON_result = model2.predict_classes(i, batch_size=1)\n",
    "        \n",
    "        if AON_result == 0:\n",
    "            results.append(0)\n",
    "        elif AON_result == 1:\n",
    "            results.append(2)\n",
    "        else:\n",
    "            results.append(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-14T09:16:21.777094Z",
     "start_time": "2018-10-14T09:16:21.755386Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3041,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = np.array(results)\n",
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-14T09:16:21.988529Z",
     "start_time": "2018-10-14T09:16:21.780096Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8339362051956594\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "score = accuracy_score(testL, results)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-14T09:16:22.317047Z",
     "start_time": "2018-10-14T09:16:21.991853Z"
    },
    "code_folding": [
     4
    ]
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pylab as plt\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cnf_matrix = confusion_matrix(testL, results)\n",
    "plot_confusion_matrix(cnf_matrix, classes=['A', '~', 'N', 'O'],\n",
    "                      title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-14T09:16:22.325798Z",
     "start_time": "2018-10-14T09:16:22.319595Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.77221325, 0.64596273, 0.90352811, 0.72401434])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "result = f1_score(testL, results, average=None)\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
