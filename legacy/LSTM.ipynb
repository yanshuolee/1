{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-10T10:04:55.525714Z",
     "start_time": "2018-10-10T10:04:53.501026Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data: (5078, 30, 300)\n",
      "Train Label:  (5078, 4)\n",
      "Vali Data:  (2032, 30, 300)\n",
      "Vali Label:  (2032, 4)\n",
      "Test Data:  (3041, 30, 300)\n",
      "Test Label:  (3041, 4)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "from keras.layers import Activation, Masking, Bidirectional, Flatten, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils, multi_gpu_model\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras import regularizers\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pylab as plt\n",
    "\n",
    "trainD = np.load(\"/home/hsiehch/30s/train_data.npy\")\n",
    "trainL = np.load(\"/home/hsiehch/30s/train_label.npy\")\n",
    "validationD = np.load(\"/home/hsiehch/30s/validation_data.npy\")\n",
    "validationL = np.load(\"/home/hsiehch/30s/validation_label.npy\")\n",
    "testD = np.load(\"/home/hsiehch/30s/test_data.npy\")\n",
    "testL = np.load(\"/home/hsiehch/30s/test_label.npy\")\n",
    "\n",
    "timestep = 30\n",
    "seq = 300\n",
    "\n",
    "trainData = trainD.reshape((trainD.shape[0], timestep, seq))\n",
    "trainLabel = np_utils.to_categorical(trainL, 4)\n",
    "validationData = validationD.reshape((validationD.shape[0], timestep, seq))\n",
    "validationLabel = np_utils.to_categorical(validationL, 4)\n",
    "testData = testD.reshape((testD.shape[0], timestep, seq))\n",
    "testLabel = np_utils.to_categorical(testL, 4)\n",
    "\n",
    "print(trainLabel)\n",
    "plt.figure(figsize=(30,4))\n",
    "plt.plot(testData[0][0])\n",
    "plt.show()\n",
    "\n",
    "# scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "# for i in range(len(trainData)):\n",
    "#     trainData[i]= scaler.fit_transform(trainData[i])\n",
    "# for i in range(len(validationData)):\n",
    "#     validationData[i] = scaler.fit_transform(validationData[i])\n",
    "# for i in range(len(testData)):\n",
    "#     testData[i]  = scaler.fit_transform(testData[i])\n",
    "\n",
    "# plt.plot(scaler.data_max_)\n",
    "# plt.show()\n",
    "\n",
    "print('Train Data:', trainData.shape)\n",
    "print('Train Label: ', trainLabel.shape)\n",
    "print('Vali Data: ', validationData.shape)\n",
    "print('Vali Label: ', validationLabel.shape)\n",
    "print('Test Data: ', testData.shape)\n",
    "print('Test Label: ', testLabel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-10T10:04:55.953073Z",
     "start_time": "2018-10-10T10:04:55.527723Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(30,4))\n",
    "plt.plot(testData[0][0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-10T10:04:57.374232Z",
     "start_time": "2018-10-10T10:04:55.955131Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(8, input_shape=(30, 300), recurrent_dropout=0.2, dropout=0.2, return_sequences=True)`\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(8, recurrent_dropout=0.2, return_sequences=True, dropout=0.2)`\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(8, recurrent_dropout=0.2, dropout=0.2)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 30, 8)             9888      \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 30, 8)             544       \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 8)                 544       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4)                 20        \n",
      "=================================================================\n",
      "Total params: 11,144\n",
      "Trainable params: 11,144\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "#, activity_regularizer=regularizers.l2(0.0001)\n",
    "# , dropout_W=0.2, dropout_U=0.2\n",
    "model.add(LSTM(8, return_sequences=True, dropout_W=0.2, dropout_U=0.2, input_shape = (timestep, seq)))\n",
    "model.add(LSTM(8, return_sequences=True, dropout_W=0.2, dropout_U=0.2))\n",
    "model.add(LSTM(8, dropout_W=0.2, dropout_U=0.2))\n",
    "model.add(Dense(8, activation='tanh'))\n",
    "model.add(Dense(4, activation='tanh'))\n",
    "model.add(Dense(4, activation='tanh'))\n",
    "model.add(Dense(4, activation='tanh'))\n",
    "model.add(Dense(4, activation=\"softmax\"))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-10T10:47:36.500026Z",
     "start_time": "2018-10-10T10:04:57.377299Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5078 samples, validate on 2032 samples\n",
      "Epoch 1/500\n",
      "5078/5078 [==============================] - 17s 3ms/step - loss: 1.1202 - acc: 0.5778 - val_loss: 1.0567 - val_acc: 0.5866\n",
      "Epoch 2/500\n",
      "5078/5078 [==============================] - 13s 2ms/step - loss: 1.0324 - acc: 0.5880 - val_loss: 1.0275 - val_acc: 0.5886\n",
      "Epoch 3/500\n",
      "5078/5078 [==============================] - 13s 2ms/step - loss: 1.0094 - acc: 0.5912 - val_loss: 1.0124 - val_acc: 0.5866\n",
      "Epoch 4/500\n",
      "5078/5078 [==============================] - 13s 3ms/step - loss: 0.9978 - acc: 0.5892 - val_loss: 1.0045 - val_acc: 0.5871\n",
      "Epoch 5/500\n",
      "5078/5078 [==============================] - 13s 2ms/step - loss: 0.9907 - acc: 0.5914 - val_loss: 1.0003 - val_acc: 0.5871\n",
      "Epoch 6/500\n",
      "5078/5078 [==============================] - 13s 2ms/step - loss: 0.9859 - acc: 0.5910 - val_loss: 0.9977 - val_acc: 0.5866\n",
      "Epoch 7/500\n",
      "5078/5078 [==============================] - 13s 2ms/step - loss: 0.9829 - acc: 0.5933 - val_loss: 0.9945 - val_acc: 0.5871\n",
      "Epoch 8/500\n",
      "5078/5078 [==============================] - 13s 3ms/step - loss: 0.9742 - acc: 0.5955 - val_loss: 0.9845 - val_acc: 0.5886\n",
      "Epoch 9/500\n",
      "5078/5078 [==============================] - 13s 3ms/step - loss: 0.9612 - acc: 0.6032 - val_loss: 0.9706 - val_acc: 0.5984\n",
      "Epoch 10/500\n",
      "5078/5078 [==============================] - 13s 3ms/step - loss: 0.9426 - acc: 0.6152 - val_loss: 0.9645 - val_acc: 0.6097\n",
      "Epoch 11/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.9347 - acc: 0.6249 - val_loss: 0.9538 - val_acc: 0.6191\n",
      "Epoch 12/500\n",
      "5078/5078 [==============================] - 13s 2ms/step - loss: 0.9210 - acc: 0.6302 - val_loss: 0.9438 - val_acc: 0.6230\n",
      "Epoch 13/500\n",
      "5078/5078 [==============================] - 13s 3ms/step - loss: 0.9131 - acc: 0.6317 - val_loss: 0.9497 - val_acc: 0.6171\n",
      "Epoch 14/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.9083 - acc: 0.6312 - val_loss: 0.9309 - val_acc: 0.6265\n",
      "Epoch 15/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.8978 - acc: 0.6404 - val_loss: 0.9440 - val_acc: 0.6186\n",
      "Epoch 16/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.8930 - acc: 0.6442 - val_loss: 0.9373 - val_acc: 0.6255\n",
      "Epoch 17/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.8918 - acc: 0.6430 - val_loss: 0.9271 - val_acc: 0.6304\n",
      "Epoch 18/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.8912 - acc: 0.6418 - val_loss: 0.9242 - val_acc: 0.6309\n",
      "Epoch 19/500\n",
      "5078/5078 [==============================] - 13s 2ms/step - loss: 0.8813 - acc: 0.6499 - val_loss: 0.9253 - val_acc: 0.6309\n",
      "Epoch 20/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.8830 - acc: 0.6491 - val_loss: 0.9201 - val_acc: 0.6289\n",
      "Epoch 21/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.8813 - acc: 0.6536 - val_loss: 0.9300 - val_acc: 0.6220\n",
      "Epoch 22/500\n",
      "5078/5078 [==============================] - 13s 3ms/step - loss: 0.8707 - acc: 0.6544 - val_loss: 0.9252 - val_acc: 0.6275\n",
      "Epoch 23/500\n",
      "5078/5078 [==============================] - 13s 2ms/step - loss: 0.8690 - acc: 0.6593 - val_loss: 0.9233 - val_acc: 0.6275\n",
      "Epoch 24/500\n",
      "5078/5078 [==============================] - 13s 3ms/step - loss: 0.8577 - acc: 0.6621 - val_loss: 0.9170 - val_acc: 0.6422\n",
      "Epoch 25/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.8599 - acc: 0.6611 - val_loss: 0.9167 - val_acc: 0.6265\n",
      "Epoch 26/500\n",
      "5078/5078 [==============================] - 13s 3ms/step - loss: 0.8551 - acc: 0.6666 - val_loss: 0.9161 - val_acc: 0.6299\n",
      "Epoch 27/500\n",
      "5078/5078 [==============================] - 13s 2ms/step - loss: 0.8545 - acc: 0.6636 - val_loss: 0.9191 - val_acc: 0.6275\n",
      "Epoch 28/500\n",
      "5078/5078 [==============================] - 13s 2ms/step - loss: 0.8482 - acc: 0.6686 - val_loss: 0.9137 - val_acc: 0.6245\n",
      "Epoch 29/500\n",
      "5078/5078 [==============================] - 13s 3ms/step - loss: 0.8462 - acc: 0.6705 - val_loss: 0.9218 - val_acc: 0.6191\n",
      "Epoch 30/500\n",
      "5078/5078 [==============================] - 13s 2ms/step - loss: 0.8449 - acc: 0.6627 - val_loss: 0.9197 - val_acc: 0.6127\n",
      "Epoch 31/500\n",
      "5078/5078 [==============================] - 13s 3ms/step - loss: 0.8359 - acc: 0.6692 - val_loss: 0.9040 - val_acc: 0.6289\n",
      "Epoch 32/500\n",
      "5078/5078 [==============================] - 13s 2ms/step - loss: 0.8367 - acc: 0.6707 - val_loss: 0.9043 - val_acc: 0.6289\n",
      "Epoch 33/500\n",
      "5078/5078 [==============================] - 13s 2ms/step - loss: 0.8323 - acc: 0.6664 - val_loss: 0.9067 - val_acc: 0.6284\n",
      "Epoch 34/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.8226 - acc: 0.6768 - val_loss: 0.8969 - val_acc: 0.6368\n",
      "Epoch 35/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.8246 - acc: 0.6694 - val_loss: 0.8999 - val_acc: 0.6304\n",
      "Epoch 36/500\n",
      "5078/5078 [==============================] - 13s 2ms/step - loss: 0.8291 - acc: 0.6670 - val_loss: 0.8889 - val_acc: 0.6284\n",
      "Epoch 37/500\n",
      "5078/5078 [==============================] - 13s 2ms/step - loss: 0.8099 - acc: 0.6792 - val_loss: 0.9013 - val_acc: 0.6191\n",
      "Epoch 38/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.8121 - acc: 0.6749 - val_loss: 0.8829 - val_acc: 0.6275\n",
      "Epoch 39/500\n",
      "5078/5078 [==============================] - 13s 2ms/step - loss: 0.8150 - acc: 0.6759 - val_loss: 0.8908 - val_acc: 0.6334\n",
      "Epoch 40/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.8082 - acc: 0.6745 - val_loss: 0.8934 - val_acc: 0.6260\n",
      "Epoch 41/500\n",
      "5078/5078 [==============================] - 13s 3ms/step - loss: 0.7998 - acc: 0.6766 - val_loss: 0.8926 - val_acc: 0.6304\n",
      "Epoch 42/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.8115 - acc: 0.6755 - val_loss: 0.8883 - val_acc: 0.6344\n",
      "Epoch 43/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.7987 - acc: 0.6818 - val_loss: 0.8918 - val_acc: 0.6309\n",
      "Epoch 44/500\n",
      "5078/5078 [==============================] - 13s 2ms/step - loss: 0.7960 - acc: 0.6816 - val_loss: 0.8962 - val_acc: 0.6309\n",
      "Epoch 45/500\n",
      "5078/5078 [==============================] - 13s 2ms/step - loss: 0.7913 - acc: 0.6847 - val_loss: 0.9012 - val_acc: 0.6196\n",
      "Epoch 46/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.8011 - acc: 0.6768 - val_loss: 0.8976 - val_acc: 0.6211\n",
      "Epoch 47/500\n",
      "5078/5078 [==============================] - 13s 3ms/step - loss: 0.7878 - acc: 0.6843 - val_loss: 0.8981 - val_acc: 0.6240\n",
      "Epoch 48/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.7908 - acc: 0.6829 - val_loss: 0.8906 - val_acc: 0.6329\n",
      "Epoch 49/500\n",
      "5078/5078 [==============================] - 13s 2ms/step - loss: 0.7872 - acc: 0.6727 - val_loss: 0.8914 - val_acc: 0.6363\n",
      "Epoch 50/500\n",
      "5078/5078 [==============================] - 13s 2ms/step - loss: 0.7936 - acc: 0.6814 - val_loss: 0.8889 - val_acc: 0.6358\n",
      "Epoch 51/500\n",
      "5078/5078 [==============================] - 13s 2ms/step - loss: 0.7861 - acc: 0.6833 - val_loss: 0.8960 - val_acc: 0.6245\n",
      "Epoch 52/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.7736 - acc: 0.6965 - val_loss: 0.8980 - val_acc: 0.6260\n",
      "Epoch 53/500\n",
      "5078/5078 [==============================] - 13s 3ms/step - loss: 0.7842 - acc: 0.6845 - val_loss: 0.8835 - val_acc: 0.6309\n",
      "Epoch 54/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.7758 - acc: 0.6891 - val_loss: 0.8959 - val_acc: 0.6250\n",
      "Epoch 55/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.7839 - acc: 0.6853 - val_loss: 0.8890 - val_acc: 0.6344\n",
      "Epoch 56/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.7777 - acc: 0.6867 - val_loss: 0.8982 - val_acc: 0.6250\n",
      "Epoch 57/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.7790 - acc: 0.6859 - val_loss: 0.9003 - val_acc: 0.6250\n",
      "Epoch 58/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.7737 - acc: 0.6816 - val_loss: 0.8926 - val_acc: 0.6294\n",
      "Epoch 59/500\n",
      "5078/5078 [==============================] - 13s 2ms/step - loss: 0.7820 - acc: 0.6896 - val_loss: 0.8931 - val_acc: 0.6275\n",
      "Epoch 60/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.7673 - acc: 0.6896 - val_loss: 0.8928 - val_acc: 0.6329\n",
      "Epoch 61/500\n",
      "5078/5078 [==============================] - 13s 2ms/step - loss: 0.7667 - acc: 0.6889 - val_loss: 0.8990 - val_acc: 0.6378\n",
      "Epoch 62/500\n",
      "5078/5078 [==============================] - 13s 2ms/step - loss: 0.7676 - acc: 0.6924 - val_loss: 0.9027 - val_acc: 0.6334\n",
      "Epoch 63/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.7656 - acc: 0.6906 - val_loss: 0.8984 - val_acc: 0.6344\n",
      "Epoch 64/500\n",
      "5078/5078 [==============================] - 13s 2ms/step - loss: 0.7634 - acc: 0.6918 - val_loss: 0.9010 - val_acc: 0.6304\n",
      "Epoch 65/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.7692 - acc: 0.6936 - val_loss: 0.8990 - val_acc: 0.6280\n",
      "Epoch 66/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.7587 - acc: 0.6955 - val_loss: 0.8945 - val_acc: 0.6314\n",
      "Epoch 67/500\n",
      "5078/5078 [==============================] - 13s 3ms/step - loss: 0.7677 - acc: 0.6924 - val_loss: 0.8946 - val_acc: 0.6334\n",
      "Epoch 68/500\n",
      "5078/5078 [==============================] - 13s 2ms/step - loss: 0.7579 - acc: 0.6902 - val_loss: 0.8969 - val_acc: 0.6378\n",
      "Epoch 69/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.7564 - acc: 0.6928 - val_loss: 0.8952 - val_acc: 0.6280\n",
      "Epoch 70/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.7606 - acc: 0.6928 - val_loss: 0.8997 - val_acc: 0.6329\n",
      "Epoch 71/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.7583 - acc: 0.6932 - val_loss: 0.8911 - val_acc: 0.6339\n",
      "Epoch 72/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.7552 - acc: 0.6934 - val_loss: 0.8992 - val_acc: 0.6284\n",
      "Epoch 73/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.7522 - acc: 0.6977 - val_loss: 0.9027 - val_acc: 0.6299\n",
      "Epoch 74/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.7536 - acc: 0.6946 - val_loss: 0.8969 - val_acc: 0.6319\n",
      "Epoch 75/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.7476 - acc: 0.6993 - val_loss: 0.9049 - val_acc: 0.6373\n",
      "Epoch 76/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.7559 - acc: 0.6926 - val_loss: 0.8928 - val_acc: 0.6373\n",
      "Epoch 77/500\n",
      "5078/5078 [==============================] - 13s 2ms/step - loss: 0.7446 - acc: 0.7007 - val_loss: 0.9016 - val_acc: 0.6304\n",
      "Epoch 78/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.7423 - acc: 0.7015 - val_loss: 0.9075 - val_acc: 0.6294\n",
      "Epoch 79/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.7431 - acc: 0.6981 - val_loss: 0.9050 - val_acc: 0.6339\n",
      "Epoch 80/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.7452 - acc: 0.6997 - val_loss: 0.9012 - val_acc: 0.6388\n",
      "Epoch 81/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.7474 - acc: 0.6938 - val_loss: 0.9115 - val_acc: 0.6289\n",
      "Epoch 82/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.7369 - acc: 0.6999 - val_loss: 0.9024 - val_acc: 0.6348\n",
      "Epoch 83/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.7405 - acc: 0.7009 - val_loss: 0.9032 - val_acc: 0.6368\n",
      "Epoch 84/500\n",
      "5078/5078 [==============================] - 13s 2ms/step - loss: 0.7393 - acc: 0.6987 - val_loss: 0.9008 - val_acc: 0.6284\n",
      "Epoch 85/500\n",
      "5078/5078 [==============================] - 13s 2ms/step - loss: 0.7381 - acc: 0.6983 - val_loss: 0.9026 - val_acc: 0.6358\n",
      "Epoch 86/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.7408 - acc: 0.6967 - val_loss: 0.9040 - val_acc: 0.6344\n",
      "Epoch 87/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.7378 - acc: 0.7001 - val_loss: 0.9025 - val_acc: 0.6334\n",
      "Epoch 88/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.7370 - acc: 0.7064 - val_loss: 0.9038 - val_acc: 0.6339\n",
      "Epoch 89/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.7361 - acc: 0.7074 - val_loss: 0.9123 - val_acc: 0.6324\n",
      "Epoch 90/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.7304 - acc: 0.7052 - val_loss: 0.9048 - val_acc: 0.6344\n",
      "Epoch 91/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.7394 - acc: 0.7034 - val_loss: 0.9035 - val_acc: 0.6294\n",
      "Epoch 92/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.7339 - acc: 0.7036 - val_loss: 0.9094 - val_acc: 0.6393\n",
      "Epoch 93/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.7265 - acc: 0.7089 - val_loss: 0.9064 - val_acc: 0.6373\n",
      "Epoch 94/500\n",
      "5078/5078 [==============================] - 13s 3ms/step - loss: 0.7309 - acc: 0.7048 - val_loss: 0.9075 - val_acc: 0.6373\n",
      "Epoch 95/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.7340 - acc: 0.7024 - val_loss: 0.9189 - val_acc: 0.6275\n",
      "Epoch 96/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.7294 - acc: 0.7123 - val_loss: 0.9107 - val_acc: 0.6363\n",
      "Epoch 97/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.7332 - acc: 0.7034 - val_loss: 0.9126 - val_acc: 0.6398\n",
      "Epoch 98/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.7267 - acc: 0.7099 - val_loss: 0.9186 - val_acc: 0.6334\n",
      "Epoch 99/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.7269 - acc: 0.7064 - val_loss: 0.9133 - val_acc: 0.6309\n",
      "Epoch 100/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.7240 - acc: 0.7093 - val_loss: 0.9146 - val_acc: 0.6329\n",
      "Epoch 101/500\n",
      "5078/5078 [==============================] - 13s 3ms/step - loss: 0.7163 - acc: 0.7127 - val_loss: 0.9105 - val_acc: 0.6339\n",
      "Epoch 102/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.7281 - acc: 0.7087 - val_loss: 0.9050 - val_acc: 0.6319\n",
      "Epoch 103/500\n",
      "5078/5078 [==============================] - 13s 2ms/step - loss: 0.7172 - acc: 0.7064 - val_loss: 0.9119 - val_acc: 0.6388\n",
      "Epoch 104/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.7180 - acc: 0.7030 - val_loss: 0.9193 - val_acc: 0.6368\n",
      "Epoch 105/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.7252 - acc: 0.7015 - val_loss: 0.9121 - val_acc: 0.6378\n",
      "Epoch 106/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.7175 - acc: 0.7080 - val_loss: 0.9113 - val_acc: 0.6284\n",
      "Epoch 107/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.7270 - acc: 0.7015 - val_loss: 0.9143 - val_acc: 0.6324\n",
      "Epoch 108/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.7210 - acc: 0.7135 - val_loss: 0.9138 - val_acc: 0.6353\n",
      "Epoch 109/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.7131 - acc: 0.7131 - val_loss: 0.9112 - val_acc: 0.6368\n",
      "Epoch 110/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.7113 - acc: 0.7127 - val_loss: 0.9099 - val_acc: 0.6348\n",
      "Epoch 111/500\n",
      "5078/5078 [==============================] - 13s 2ms/step - loss: 0.7164 - acc: 0.7054 - val_loss: 0.9128 - val_acc: 0.6314\n",
      "Epoch 112/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.7083 - acc: 0.7091 - val_loss: 0.9225 - val_acc: 0.6304\n",
      "Epoch 113/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.7066 - acc: 0.7141 - val_loss: 0.9300 - val_acc: 0.6284\n",
      "Epoch 114/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.7138 - acc: 0.7127 - val_loss: 0.9149 - val_acc: 0.6348\n",
      "Epoch 115/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.7130 - acc: 0.7154 - val_loss: 0.9182 - val_acc: 0.6284\n",
      "Epoch 116/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.7120 - acc: 0.7135 - val_loss: 0.9208 - val_acc: 0.6329\n",
      "Epoch 117/500\n",
      "5078/5078 [==============================] - 13s 2ms/step - loss: 0.7146 - acc: 0.7093 - val_loss: 0.9199 - val_acc: 0.6353\n",
      "Epoch 118/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.7160 - acc: 0.7080 - val_loss: 0.9166 - val_acc: 0.6304\n",
      "Epoch 119/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.7073 - acc: 0.7152 - val_loss: 0.9233 - val_acc: 0.6314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.7100 - acc: 0.7135 - val_loss: 0.9145 - val_acc: 0.6329\n",
      "Epoch 121/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.7058 - acc: 0.7113 - val_loss: 0.9230 - val_acc: 0.6334\n",
      "Epoch 122/500\n",
      "5078/5078 [==============================] - 13s 2ms/step - loss: 0.7164 - acc: 0.7089 - val_loss: 0.9197 - val_acc: 0.6309\n",
      "Epoch 123/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.7071 - acc: 0.7147 - val_loss: 0.9177 - val_acc: 0.6304\n",
      "Epoch 124/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.7176 - acc: 0.7111 - val_loss: 0.9231 - val_acc: 0.6324\n",
      "Epoch 125/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6999 - acc: 0.7160 - val_loss: 0.9253 - val_acc: 0.6348\n",
      "Epoch 126/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.7048 - acc: 0.7219 - val_loss: 0.9236 - val_acc: 0.6368\n",
      "Epoch 127/500\n",
      "5078/5078 [==============================] - 13s 2ms/step - loss: 0.7072 - acc: 0.7129 - val_loss: 0.9121 - val_acc: 0.6398\n",
      "Epoch 128/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.7018 - acc: 0.7172 - val_loss: 0.9207 - val_acc: 0.6363\n",
      "Epoch 129/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6982 - acc: 0.7145 - val_loss: 0.9271 - val_acc: 0.6329\n",
      "Epoch 130/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6948 - acc: 0.7127 - val_loss: 0.9215 - val_acc: 0.6363\n",
      "Epoch 131/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6999 - acc: 0.7148 - val_loss: 0.9286 - val_acc: 0.6378\n",
      "Epoch 132/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6998 - acc: 0.7176 - val_loss: 0.9445 - val_acc: 0.6186\n",
      "Epoch 133/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6989 - acc: 0.7204 - val_loss: 0.9176 - val_acc: 0.6398\n",
      "Epoch 134/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.7012 - acc: 0.7131 - val_loss: 0.9241 - val_acc: 0.6393\n",
      "Epoch 135/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6823 - acc: 0.7158 - val_loss: 0.9369 - val_acc: 0.6348\n",
      "Epoch 136/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6993 - acc: 0.7200 - val_loss: 0.9450 - val_acc: 0.6284\n",
      "Epoch 137/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6890 - acc: 0.7229 - val_loss: 0.9317 - val_acc: 0.6348\n",
      "Epoch 138/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6950 - acc: 0.7148 - val_loss: 0.9226 - val_acc: 0.6398\n",
      "Epoch 139/500\n",
      "5078/5078 [==============================] - 13s 2ms/step - loss: 0.6976 - acc: 0.7147 - val_loss: 0.9221 - val_acc: 0.6407\n",
      "Epoch 140/500\n",
      "5078/5078 [==============================] - 13s 3ms/step - loss: 0.6915 - acc: 0.7235 - val_loss: 0.9247 - val_acc: 0.6348\n",
      "Epoch 141/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6857 - acc: 0.7190 - val_loss: 0.9235 - val_acc: 0.6403\n",
      "Epoch 142/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6915 - acc: 0.7194 - val_loss: 0.9264 - val_acc: 0.6407\n",
      "Epoch 143/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6929 - acc: 0.7174 - val_loss: 0.9502 - val_acc: 0.6201\n",
      "Epoch 144/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6936 - acc: 0.7184 - val_loss: 0.9326 - val_acc: 0.6353\n",
      "Epoch 145/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6882 - acc: 0.7219 - val_loss: 0.9262 - val_acc: 0.6403\n",
      "Epoch 146/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6926 - acc: 0.7135 - val_loss: 0.9358 - val_acc: 0.6383\n",
      "Epoch 147/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6851 - acc: 0.7231 - val_loss: 0.9281 - val_acc: 0.6378\n",
      "Epoch 148/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6847 - acc: 0.7241 - val_loss: 0.9325 - val_acc: 0.6373\n",
      "Epoch 149/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6871 - acc: 0.7204 - val_loss: 0.9353 - val_acc: 0.6344\n",
      "Epoch 150/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6913 - acc: 0.7221 - val_loss: 0.9227 - val_acc: 0.6393\n",
      "Epoch 151/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6841 - acc: 0.7190 - val_loss: 0.9356 - val_acc: 0.6299\n",
      "Epoch 152/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6759 - acc: 0.7247 - val_loss: 0.9388 - val_acc: 0.6378\n",
      "Epoch 153/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6867 - acc: 0.7227 - val_loss: 0.9285 - val_acc: 0.6348\n",
      "Epoch 154/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6783 - acc: 0.7261 - val_loss: 0.9386 - val_acc: 0.6353\n",
      "Epoch 155/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6824 - acc: 0.7237 - val_loss: 0.9340 - val_acc: 0.6353\n",
      "Epoch 156/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6783 - acc: 0.7241 - val_loss: 0.9364 - val_acc: 0.6378\n",
      "Epoch 157/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6838 - acc: 0.7192 - val_loss: 0.9315 - val_acc: 0.6334\n",
      "Epoch 158/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6883 - acc: 0.7210 - val_loss: 0.9276 - val_acc: 0.6275\n",
      "Epoch 159/500\n",
      "5078/5078 [==============================] - 13s 2ms/step - loss: 0.6776 - acc: 0.7275 - val_loss: 0.9271 - val_acc: 0.6388\n",
      "Epoch 160/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6733 - acc: 0.7302 - val_loss: 0.9299 - val_acc: 0.6358\n",
      "Epoch 161/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6682 - acc: 0.7328 - val_loss: 0.9370 - val_acc: 0.6378\n",
      "Epoch 162/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6704 - acc: 0.7328 - val_loss: 0.9462 - val_acc: 0.6250\n",
      "Epoch 163/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6728 - acc: 0.7326 - val_loss: 0.9499 - val_acc: 0.6334\n",
      "Epoch 164/500\n",
      "5078/5078 [==============================] - 13s 2ms/step - loss: 0.6780 - acc: 0.7326 - val_loss: 0.9382 - val_acc: 0.6412\n",
      "Epoch 165/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6747 - acc: 0.7306 - val_loss: 0.9496 - val_acc: 0.6304\n",
      "Epoch 166/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6707 - acc: 0.7241 - val_loss: 0.9354 - val_acc: 0.6407\n",
      "Epoch 167/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6690 - acc: 0.7255 - val_loss: 0.9390 - val_acc: 0.6353\n",
      "Epoch 168/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6746 - acc: 0.7286 - val_loss: 0.9371 - val_acc: 0.6284\n",
      "Epoch 169/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6643 - acc: 0.7332 - val_loss: 0.9464 - val_acc: 0.6299\n",
      "Epoch 170/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6663 - acc: 0.7336 - val_loss: 0.9560 - val_acc: 0.6314\n",
      "Epoch 171/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6761 - acc: 0.7290 - val_loss: 0.9412 - val_acc: 0.6314\n",
      "Epoch 172/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6655 - acc: 0.7302 - val_loss: 0.9545 - val_acc: 0.6260\n",
      "Epoch 173/500\n",
      "5078/5078 [==============================] - 13s 2ms/step - loss: 0.6748 - acc: 0.7296 - val_loss: 0.9436 - val_acc: 0.6275\n",
      "Epoch 174/500\n",
      "5078/5078 [==============================] - 13s 2ms/step - loss: 0.6662 - acc: 0.7338 - val_loss: 0.9438 - val_acc: 0.6348\n",
      "Epoch 175/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6764 - acc: 0.7219 - val_loss: 0.9453 - val_acc: 0.6339\n",
      "Epoch 176/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6778 - acc: 0.7200 - val_loss: 0.9343 - val_acc: 0.6255\n",
      "Epoch 177/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6738 - acc: 0.7294 - val_loss: 0.9496 - val_acc: 0.6250\n",
      "Epoch 178/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6686 - acc: 0.7300 - val_loss: 0.9431 - val_acc: 0.6299\n",
      "Epoch 179/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6748 - acc: 0.7322 - val_loss: 0.9313 - val_acc: 0.6447\n",
      "Epoch 180/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6610 - acc: 0.7359 - val_loss: 0.9429 - val_acc: 0.6324\n",
      "Epoch 181/500\n",
      "5078/5078 [==============================] - 13s 2ms/step - loss: 0.6728 - acc: 0.7227 - val_loss: 0.9377 - val_acc: 0.6368\n",
      "Epoch 182/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6627 - acc: 0.7343 - val_loss: 0.9469 - val_acc: 0.6348\n",
      "Epoch 183/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6677 - acc: 0.7243 - val_loss: 0.9424 - val_acc: 0.6378\n",
      "Epoch 184/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6649 - acc: 0.7330 - val_loss: 0.9512 - val_acc: 0.6319\n",
      "Epoch 185/500\n",
      "5078/5078 [==============================] - 13s 2ms/step - loss: 0.6555 - acc: 0.7383 - val_loss: 0.9701 - val_acc: 0.6255\n",
      "Epoch 186/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6611 - acc: 0.7320 - val_loss: 0.9463 - val_acc: 0.6363\n",
      "Epoch 187/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6531 - acc: 0.7395 - val_loss: 0.9523 - val_acc: 0.6447\n",
      "Epoch 188/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6671 - acc: 0.7280 - val_loss: 0.9508 - val_acc: 0.6255\n",
      "Epoch 189/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6620 - acc: 0.7332 - val_loss: 0.9562 - val_acc: 0.6393\n",
      "Epoch 190/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6671 - acc: 0.7304 - val_loss: 0.9486 - val_acc: 0.6471\n",
      "Epoch 191/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6663 - acc: 0.7300 - val_loss: 0.9585 - val_acc: 0.6245\n",
      "Epoch 192/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6570 - acc: 0.7314 - val_loss: 0.9521 - val_acc: 0.6363\n",
      "Epoch 193/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6551 - acc: 0.7338 - val_loss: 0.9497 - val_acc: 0.6407\n",
      "Epoch 194/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6666 - acc: 0.7290 - val_loss: 0.9447 - val_acc: 0.6447\n",
      "Epoch 195/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6519 - acc: 0.7320 - val_loss: 0.9449 - val_acc: 0.6383\n",
      "Epoch 196/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6572 - acc: 0.7306 - val_loss: 0.9366 - val_acc: 0.6324\n",
      "Epoch 197/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6639 - acc: 0.7261 - val_loss: 0.9516 - val_acc: 0.6319\n",
      "Epoch 198/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6583 - acc: 0.7365 - val_loss: 0.9624 - val_acc: 0.6250\n",
      "Epoch 199/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6626 - acc: 0.7300 - val_loss: 0.9469 - val_acc: 0.6319\n",
      "Epoch 200/500\n",
      "5078/5078 [==============================] - 13s 3ms/step - loss: 0.6575 - acc: 0.7357 - val_loss: 0.9501 - val_acc: 0.6344\n",
      "Epoch 201/500\n",
      "5078/5078 [==============================] - 13s 2ms/step - loss: 0.6584 - acc: 0.7345 - val_loss: 0.9521 - val_acc: 0.6329\n",
      "Epoch 202/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6683 - acc: 0.7300 - val_loss: 0.9445 - val_acc: 0.6260\n",
      "Epoch 203/500\n",
      "5078/5078 [==============================] - 13s 2ms/step - loss: 0.6673 - acc: 0.7265 - val_loss: 0.9543 - val_acc: 0.6265\n",
      "Epoch 204/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6519 - acc: 0.7357 - val_loss: 0.9445 - val_acc: 0.6304\n",
      "Epoch 205/500\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.6459 - acc: 0.7324 - val_loss: 0.9690 - val_acc: 0.6250\n",
      "Epoch 206/500\n",
      "4800/5078 [===========================>..] - ETA: 0s - loss: 0.6490 - acc: 0.7369"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-474fca50e016>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m                           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidationData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidationLabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                           \u001b[0;31m#callbacks=[graph],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m                           \u001b[0;31m#shuffle=False,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                           )\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    963\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1667\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1669\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1204\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1206\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1207\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "adam = Adam(lr = 0.001)\n",
    "model.compile(optimizer = \"Adam\", loss = \"categorical_crossentropy\", metrics = ['accuracy'])\n",
    "# graph = TensorBoard()\n",
    "train_history = model.fit(x = trainData, \n",
    "                          y = trainLabel,\n",
    "                          epochs=500,\n",
    "                          validation_data=(validationData, validationLabel),\n",
    "                          #callbacks=[graph],\n",
    "                          batch_size=80,\n",
    "                          #shuffle=False,\n",
    "                          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-10T10:47:36.501234Z",
     "start_time": "2018-10-10T10:04:55.170Z"
    }
   },
   "outputs": [],
   "source": [
    "import pylab as plt\n",
    "def history_display(hist, train, validation):\n",
    "    plt.plot(hist.history[train])\n",
    "    plt.plot(hist.history[validation])\n",
    "    plt.title('Train History')\n",
    "    plt.ylabel(train)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show\n",
    "    \n",
    "def show_plot(flag, hist):\n",
    "    if flag == 'acc':\n",
    "        history_display(hist, 'acc', 'val_acc')\n",
    "    elif flag == 'loss':\n",
    "        history_display(hist, 'loss', 'val_loss')\n",
    "    else:\n",
    "        print('Invalid!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-10T10:47:36.502355Z",
     "start_time": "2018-10-10T10:04:55.170Z"
    }
   },
   "outputs": [],
   "source": [
    "show_plot('acc', train_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-10T10:47:36.503426Z",
     "start_time": "2018-10-10T10:04:55.172Z"
    }
   },
   "outputs": [],
   "source": [
    "show_plot('loss', train_history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
