{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## paper from http://www.cinc.org/archives/2017/pdf/161-460.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/hsiehch/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/hsiehch/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/hsiehch/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/hsiehch/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/hsiehch/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/hsiehch/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv1D, MaxPooling1D, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, Bidirectional, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_7 (Conv1D)            (None, 9000, 10)          110       \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 9000, 10)          40        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 9000, 10)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 500, 10)           0         \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 500, 100)          44400     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 500, 100)          400       \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 500, 100)          80400     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 500, 100)          400       \n",
      "_________________________________________________________________\n",
      "lstm_13 (LSTM)               (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 404       \n",
      "=================================================================\n",
      "Total params: 206,954\n",
      "Trainable params: 206,334\n",
      "Non-trainable params: 620\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(filters = 10, kernel_size = 10, input_shape = (9000,1), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size = 18))\n",
    "\n",
    "model.add(LSTM(100, recurrent_dropout=0.1, return_sequences=True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LSTM(100, recurrent_dropout=0.1, return_sequences=True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LSTM(100, recurrent_dropout=0.1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## paper from http://www.cinc.org/archives/2017/pdf/360-239.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/hsiehch/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/hsiehch/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/hsiehch/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/hsiehch/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/hsiehch/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/hsiehch/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 18000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 18000, 16)    1040        input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 18000, 16)    0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 18000, 16)    64          activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 18000, 16)    16400       batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 18000, 16)    0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 18000, 16)    64          activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 18000, 16)    0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 18000, 16)    16400       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 9000, 16)     0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 9000, 16)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 9000, 16)     0           max_pooling1d_1[0][0]            \n",
      "                                                                 max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 9000, 16)     64          add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 9000, 16)     0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 9000, 16)     0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 9000, 16)     16400       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 9000, 16)     64          conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 9000, 16)     0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 9000, 16)     0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 9000, 16)     16400       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 9000, 16)     0           conv1d_5[0][0]                   \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 9000, 16)     64          add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 9000, 16)     0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 9000, 16)     0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 9000, 16)     16400       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 9000, 16)     64          conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 9000, 16)     0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 9000, 16)     0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 9000, 16)     16400       dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 4500, 16)     0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 4500, 16)     0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 4500, 16)     0           max_pooling1d_4[0][0]            \n",
      "                                                                 max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 4500, 16)     64          add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 4500, 16)     0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 4500, 16)     0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 4500, 16)     16400       dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 4500, 16)     64          conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 4500, 16)     0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 4500, 16)     0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 4500, 16)     16400       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 4500, 16)     0           conv1d_9[0][0]                   \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 4500, 16)     64          add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 4500, 16)     0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 4500, 16)     0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 4500, 16)     16400       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 4500, 16)     64          conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 4500, 16)     0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 4500, 16)     0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 4500, 16)     16400       dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 2250, 16)     0           conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 2250, 16)     0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 2250, 16)     0           max_pooling1d_6[0][0]            \n",
      "                                                                 max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 2250, 16)     64          add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 2250, 16)     0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 2250, 16)     0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 2250, 16)     32784       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 2250, 16)     64          conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 2250, 16)     0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 2250, 16)     0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 2250, 16)     32784       dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 2250, 16)     0           conv1d_13[0][0]                  \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 2250, 16)     64          add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 2250, 16)     0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 2250, 16)     0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 2250, 16)     32784       dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 2250, 16)     64          conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 2250, 16)     0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 2250, 16)     0           activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 2250, 16)     32784       dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1D)  (None, 1125, 16)     0           conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1D)  (None, 1125, 16)     0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 1125, 16)     0           max_pooling1d_8[0][0]            \n",
      "                                                                 max_pooling1d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 1125, 16)     64          add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 1125, 16)     0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 1125, 16)     0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 1125, 16)     32784       dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 1125, 16)     64          conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 1125, 16)     0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 1125, 16)     0           activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 1125, 16)     32784       dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 1125, 16)     0           conv1d_17[0][0]                  \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 1125, 16)     64          add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 1125, 16)     0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 1125, 16)     0           activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 1125, 16)     32784       dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 1125, 16)     64          conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 1125, 16)     0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 1125, 16)     0           activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 1125, 16)     32784       dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling1D) (None, 562, 16)      0           conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1D)  (None, 562, 16)      0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 562, 16)      0           max_pooling1d_10[0][0]           \n",
      "                                                                 max_pooling1d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 562, 16)      64          add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 562, 16)      0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 562, 16)      0           activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 562, 16)      49168       dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 562, 16)      64          conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 562, 16)      0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 562, 16)      0           activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 562, 16)      49168       dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 562, 16)      0           conv1d_21[0][0]                  \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 562, 16)      64          add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 562, 16)      0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 562, 16)      0           activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 562, 16)      49168       dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 562, 16)      64          conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 562, 16)      0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 562, 16)      0           activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 562, 16)      49168       dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling1D) (None, 281, 16)      0           conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling1D) (None, 281, 16)      0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 281, 16)      0           max_pooling1d_12[0][0]           \n",
      "                                                                 max_pooling1d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 281, 16)      64          add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 281, 16)      0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 281, 16)      0           activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 281, 16)      49168       dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 281, 16)      64          conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 281, 16)      0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 281, 16)      0           activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 281, 16)      49168       dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 281, 16)      0           conv1d_25[0][0]                  \n",
      "                                                                 add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 281, 16)      64          add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 281, 16)      0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 281, 16)      0           activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, 281, 16)      49168       dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 281, 16)      64          conv1d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 281, 16)      0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 281, 16)      0           activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 281, 16)      49168       dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling1D) (None, 140, 16)      0           conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling1D) (None, 140, 16)      0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 140, 16)      0           max_pooling1d_14[0][0]           \n",
      "                                                                 max_pooling1d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 140, 16)      64          add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 140, 16)      0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 140, 16)      0           activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)              (None, 140, 16)      65552       dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 140, 16)      64          conv1d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 140, 16)      0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 140, 16)      0           activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_29 (Conv1D)              (None, 140, 16)      65552       dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 140, 16)      0           conv1d_29[0][0]                  \n",
      "                                                                 add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 140, 16)      64          add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 140, 16)      0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 140, 16)      0           activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, 140, 16)      65552       dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 140, 16)      64          conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 140, 16)      0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 140, 16)      0           activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_31 (Conv1D)              (None, 140, 16)      65552       dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling1D) (None, 70, 16)       0           conv1d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling1D) (None, 70, 16)       0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 70, 16)       0           max_pooling1d_16[0][0]           \n",
      "                                                                 max_pooling1d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 70, 16)       64          add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 70, 16)       0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 70, 16)       0           activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_32 (Conv1D)              (None, 70, 16)       65552       dropout_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 70, 16)       64          conv1d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 70, 16)       0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 70, 16)       0           activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, 70, 16)       65552       dropout_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 70, 16)       0           conv1d_33[0][0]                  \n",
      "                                                                 add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 70, 16)       64          add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 70, 16)       0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1120)         0           activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 4)            4484        flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,220,564\n",
      "Trainable params: 1,219,508\n",
      "Non-trainable params: 1,056\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsiehch/.local/lib/python3.5/site-packages/keras/engine/saving.py:327: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "  warnings.warn('Error in loading the saved optimizer '\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading model\")    \n",
    "from keras.models import load_model\n",
    "model = load_model('CNN_aug_1min.h5')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### source code from https://github.com/awni/ecg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def _bn_relu(layer, dropout=0, **params):\n",
    "    from keras.layers import BatchNormalization\n",
    "    from keras.layers import Activation\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = Activation(params[\"conv_activation\"])(layer)\n",
    "\n",
    "    if dropout > 0:\n",
    "        from keras.layers import Dropout\n",
    "        layer = Dropout(params[\"conv_dropout\"])(layer)\n",
    "\n",
    "    return layer\n",
    "\n",
    "def add_conv_weight(\n",
    "        layer,\n",
    "        filter_length,\n",
    "        num_filters,\n",
    "        subsample_length=1,\n",
    "        **params):\n",
    "    from keras.layers import Conv1D \n",
    "    layer = Conv1D(\n",
    "        filters=num_filters,\n",
    "        kernel_size=filter_length,\n",
    "        strides=subsample_length,\n",
    "        padding='same',\n",
    "        kernel_initializer=params[\"conv_init\"])(layer)\n",
    "    return layer\n",
    "\n",
    "\n",
    "def add_conv_layers(layer, **params):\n",
    "    for subsample_length in params[\"conv_subsample_lengths\"]:\n",
    "        layer = add_conv_weight(\n",
    "                    layer,\n",
    "                    params[\"conv_filter_length\"],\n",
    "                    params[\"conv_num_filters_start\"],\n",
    "                    subsample_length=subsample_length,\n",
    "                    **params)\n",
    "        layer = _bn_relu(layer, **params)\n",
    "    return layer\n",
    "\n",
    "def resnet_block(\n",
    "        layer,\n",
    "        num_filters,\n",
    "        subsample_length,\n",
    "        block_index,\n",
    "        **params):\n",
    "    from keras.layers import Add \n",
    "    from keras.layers import MaxPooling1D\n",
    "    from keras.layers.core import Lambda\n",
    "\n",
    "    def zeropad(x):\n",
    "        y = K.zeros_like(x)\n",
    "        return K.concatenate([x, y], axis=2)\n",
    "\n",
    "    def zeropad_output_shape(input_shape):\n",
    "        shape = list(input_shape)\n",
    "        assert len(shape) == 3\n",
    "        shape[2] *= 2\n",
    "        return tuple(shape)\n",
    "\n",
    "    shortcut = MaxPooling1D(pool_size=subsample_length, padding='same')(layer)\n",
    "    zero_pad = (block_index % params[\"conv_increase_channels_at\"]) == 0 \\\n",
    "        and block_index > 0\n",
    "    if zero_pad is True:\n",
    "        shortcut = Lambda(zeropad, output_shape=zeropad_output_shape)(shortcut)\n",
    "\n",
    "    for i in range(params[\"conv_num_skip\"]):\n",
    "        if not (block_index == 0 and i == 0):\n",
    "            layer = _bn_relu(\n",
    "                layer,\n",
    "                dropout=params[\"conv_dropout\"] if i > 0 else 0,\n",
    "                **params)\n",
    "        layer = add_conv_weight(\n",
    "            layer,\n",
    "            params[\"conv_filter_length\"],\n",
    "            num_filters,\n",
    "            subsample_length if i == 0 else 1,\n",
    "            **params)\n",
    "    layer = Add()([shortcut, layer])\n",
    "    return layer\n",
    "\n",
    "def get_num_filters_at_index(index, num_start_filters, **params):\n",
    "    return 2**int(index / params[\"conv_increase_channels_at\"]) \\\n",
    "        * num_start_filters\n",
    "\n",
    "def add_resnet_layers(layer, **params):\n",
    "    layer = add_conv_weight(\n",
    "        layer,\n",
    "        params[\"conv_filter_length\"],\n",
    "        params[\"conv_num_filters_start\"],\n",
    "        subsample_length=1,\n",
    "        **params)\n",
    "    layer = _bn_relu(layer, **params)\n",
    "    for index, subsample_length in enumerate(params[\"conv_subsample_lengths\"]):\n",
    "        num_filters = get_num_filters_at_index(\n",
    "            index, params[\"conv_num_filters_start\"], **params)\n",
    "        layer = resnet_block(\n",
    "            layer,\n",
    "            num_filters,\n",
    "            subsample_length,\n",
    "            index,\n",
    "            **params)\n",
    "    layer = _bn_relu(layer, **params)\n",
    "    return layer\n",
    "\n",
    "def add_output_layer(layer, **params):\n",
    "    from keras.layers.core import Dense, Activation\n",
    "    from keras.layers.wrappers import TimeDistributed\n",
    "    layer = TimeDistributed(Dense(params[\"num_categories\"]))(layer)\n",
    "    return Activation('softmax')(layer)\n",
    "\n",
    "def add_compile(model, **params):\n",
    "    from keras.optimizers import Adam\n",
    "    optimizer = Adam(\n",
    "        lr=params[\"learning_rate\"],\n",
    "        clipnorm=params.get(\"clipnorm\", 1))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "def build_network(**params):\n",
    "    from keras.models import Model\n",
    "    from keras.layers import Input\n",
    "    inputs = Input(shape=params['input_shape'],\n",
    "                   dtype='float32',\n",
    "                   name='inputs')\n",
    "\n",
    "    if params.get('is_regular_conv', False):\n",
    "        layer = add_conv_layers(inputs, **params)\n",
    "    else:\n",
    "        layer = add_resnet_layers(inputs, **params)\n",
    "\n",
    "    output = add_output_layer(layer, **params)\n",
    "    model = Model(inputs=[inputs], outputs=[output])\n",
    "    if params.get(\"compile\", True):\n",
    "        add_compile(model, **params)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"conv_subsample_lengths\": [1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2],\n",
    "    \"conv_filter_length\": 16,\n",
    "    \"conv_num_filters_start\": 32,\n",
    "    \"conv_init\": \"he_normal\",\n",
    "    \"conv_activation\": \"relu\",\n",
    "    \"conv_dropout\": 0.2,\n",
    "    \"conv_num_skip\": 2,\n",
    "    \"conv_increase_channels_at\": 4,\n",
    "\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"batch_size\": 32,\n",
    "\n",
    "    \"train\": \"examples/cinc17/train.json\",\n",
    "    \"dev\": \"examples/cinc17/dev.json\",\n",
    "\n",
    "    \"generator\": True,\n",
    "\n",
    "    \"save_dir\": \"saved\",\n",
    "    'input_shape': (9000,1),\n",
    "    'num_categories': 4\n",
    "}\n",
    "model = build_network(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             (None, 9000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_91 (Conv1D)              (None, 9000, 32)     544         inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 9000, 32)     128         conv1d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 9000, 32)     0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_92 (Conv1D)              (None, 9000, 32)     16416       activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 9000, 32)     128         conv1d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 9000, 32)     0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_43 (Dropout)            (None, 9000, 32)     0           activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling1D) (None, 9000, 32)     0           activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_93 (Conv1D)              (None, 9000, 32)     16416       dropout_43[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_43 (Add)                    (None, 9000, 32)     0           max_pooling1d_43[0][0]           \n",
      "                                                                 conv1d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 9000, 32)     128         add_43[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 9000, 32)     0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_94 (Conv1D)              (None, 4500, 32)     16416       activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 4500, 32)     128         conv1d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 4500, 32)     0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_44 (Dropout)            (None, 4500, 32)     0           activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling1D) (None, 4500, 32)     0           add_43[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_95 (Conv1D)              (None, 4500, 32)     16416       dropout_44[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_44 (Add)                    (None, 4500, 32)     0           max_pooling1d_44[0][0]           \n",
      "                                                                 conv1d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 4500, 32)     128         add_44[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 4500, 32)     0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_96 (Conv1D)              (None, 4500, 32)     16416       activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 4500, 32)     128         conv1d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 4500, 32)     0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_45 (Dropout)            (None, 4500, 32)     0           activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling1D) (None, 4500, 32)     0           add_44[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_97 (Conv1D)              (None, 4500, 32)     16416       dropout_45[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_45 (Add)                    (None, 4500, 32)     0           max_pooling1d_45[0][0]           \n",
      "                                                                 conv1d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 4500, 32)     128         add_45[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 4500, 32)     0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_98 (Conv1D)              (None, 2250, 32)     16416       activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 2250, 32)     128         conv1d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 2250, 32)     0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_46 (Dropout)            (None, 2250, 32)     0           activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling1D) (None, 2250, 32)     0           add_45[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_99 (Conv1D)              (None, 2250, 32)     16416       dropout_46[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_46 (Add)                    (None, 2250, 32)     0           max_pooling1d_46[0][0]           \n",
      "                                                                 conv1d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 2250, 32)     128         add_46[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 2250, 32)     0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_100 (Conv1D)             (None, 2250, 64)     32832       activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 2250, 64)     256         conv1d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 2250, 64)     0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling1D) (None, 2250, 32)     0           add_46[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_47 (Dropout)            (None, 2250, 64)     0           activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 2250, 64)     0           max_pooling1d_47[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_101 (Conv1D)             (None, 2250, 64)     65600       dropout_47[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_47 (Add)                    (None, 2250, 64)     0           lambda_7[0][0]                   \n",
      "                                                                 conv1d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 2250, 64)     256         add_47[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 2250, 64)     0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_102 (Conv1D)             (None, 1125, 64)     65600       activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 1125, 64)     256         conv1d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 1125, 64)     0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_48 (Dropout)            (None, 1125, 64)     0           activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling1D) (None, 1125, 64)     0           add_47[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_103 (Conv1D)             (None, 1125, 64)     65600       dropout_48[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_48 (Add)                    (None, 1125, 64)     0           max_pooling1d_48[0][0]           \n",
      "                                                                 conv1d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 1125, 64)     256         add_48[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 1125, 64)     0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_104 (Conv1D)             (None, 1125, 64)     65600       activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 1125, 64)     256         conv1d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 1125, 64)     0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_49 (Dropout)            (None, 1125, 64)     0           activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling1D) (None, 1125, 64)     0           add_48[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_105 (Conv1D)             (None, 1125, 64)     65600       dropout_49[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_49 (Add)                    (None, 1125, 64)     0           max_pooling1d_49[0][0]           \n",
      "                                                                 conv1d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 1125, 64)     256         add_49[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 1125, 64)     0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_106 (Conv1D)             (None, 563, 64)      65600       activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 563, 64)      256         conv1d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 563, 64)      0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_50 (Dropout)            (None, 563, 64)      0           activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling1D) (None, 563, 64)      0           add_49[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_107 (Conv1D)             (None, 563, 64)      65600       dropout_50[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_50 (Add)                    (None, 563, 64)      0           max_pooling1d_50[0][0]           \n",
      "                                                                 conv1d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 563, 64)      256         add_50[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 563, 64)      0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_108 (Conv1D)             (None, 563, 128)     131200      activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 563, 128)     512         conv1d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 563, 128)     0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling1D) (None, 563, 64)      0           add_50[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_51 (Dropout)            (None, 563, 128)     0           activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 563, 128)     0           max_pooling1d_51[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_109 (Conv1D)             (None, 563, 128)     262272      dropout_51[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_51 (Add)                    (None, 563, 128)     0           lambda_8[0][0]                   \n",
      "                                                                 conv1d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 563, 128)     512         add_51[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 563, 128)     0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_110 (Conv1D)             (None, 282, 128)     262272      activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 282, 128)     512         conv1d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 282, 128)     0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_52 (Dropout)            (None, 282, 128)     0           activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling1D) (None, 282, 128)     0           add_51[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_111 (Conv1D)             (None, 282, 128)     262272      dropout_52[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_52 (Add)                    (None, 282, 128)     0           max_pooling1d_52[0][0]           \n",
      "                                                                 conv1d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 282, 128)     512         add_52[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 282, 128)     0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_112 (Conv1D)             (None, 282, 128)     262272      activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 282, 128)     512         conv1d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 282, 128)     0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_53 (Dropout)            (None, 282, 128)     0           activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling1D) (None, 282, 128)     0           add_52[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_113 (Conv1D)             (None, 282, 128)     262272      dropout_53[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_53 (Add)                    (None, 282, 128)     0           max_pooling1d_53[0][0]           \n",
      "                                                                 conv1d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 282, 128)     512         add_53[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 282, 128)     0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_114 (Conv1D)             (None, 141, 128)     262272      activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 141, 128)     512         conv1d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 141, 128)     0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_54 (Dropout)            (None, 141, 128)     0           activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling1D) (None, 141, 128)     0           add_53[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_115 (Conv1D)             (None, 141, 128)     262272      dropout_54[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_54 (Add)                    (None, 141, 128)     0           max_pooling1d_54[0][0]           \n",
      "                                                                 conv1d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 141, 128)     512         add_54[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 141, 128)     0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_116 (Conv1D)             (None, 141, 256)     524544      activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 141, 256)     1024        conv1d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 141, 256)     0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling1D) (None, 141, 128)     0           add_54[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_55 (Dropout)            (None, 141, 256)     0           activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 141, 256)     0           max_pooling1d_55[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_117 (Conv1D)             (None, 141, 256)     1048832     dropout_55[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_55 (Add)                    (None, 141, 256)     0           lambda_9[0][0]                   \n",
      "                                                                 conv1d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 141, 256)     1024        add_55[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 141, 256)     0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_118 (Conv1D)             (None, 71, 256)      1048832     activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 71, 256)      1024        conv1d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 71, 256)      0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_56 (Dropout)            (None, 71, 256)      0           activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling1D) (None, 71, 256)      0           add_55[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_119 (Conv1D)             (None, 71, 256)      1048832     dropout_56[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_56 (Add)                    (None, 71, 256)      0           max_pooling1d_56[0][0]           \n",
      "                                                                 conv1d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 71, 256)      1024        add_56[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 71, 256)      0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_120 (Conv1D)             (None, 71, 256)      1048832     activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 71, 256)      1024        conv1d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 71, 256)      0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_57 (Dropout)            (None, 71, 256)      0           activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling1D) (None, 71, 256)      0           add_56[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_121 (Conv1D)             (None, 71, 256)      1048832     dropout_57[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_57 (Add)                    (None, 71, 256)      0           max_pooling1d_57[0][0]           \n",
      "                                                                 conv1d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 71, 256)      1024        add_57[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 71, 256)      0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_122 (Conv1D)             (None, 36, 256)      1048832     activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 36, 256)      1024        conv1d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 36, 256)      0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_58 (Dropout)            (None, 36, 256)      0           activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling1D) (None, 36, 256)      0           add_57[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_123 (Conv1D)             (None, 36, 256)      1048832     dropout_58[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_58 (Add)                    (None, 36, 256)      0           max_pooling1d_58[0][0]           \n",
      "                                                                 conv1d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 36, 256)      1024        add_58[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 36, 256)      0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 36, 4)        1028        activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 36, 4)        0           time_distributed_1[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 10,473,892\n",
      "Trainable params: 10,466,148\n",
      "Non-trainable params: 7,744\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
