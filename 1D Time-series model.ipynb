{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 30 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-16T14:33:11.699806Z",
     "start_time": "2018-10-16T14:33:09.675090Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data: (5078, 9000, 1)\n",
      "Train Label:  (5078, 4)\n",
      "Vali Data:  (2032, 9000, 1)\n",
      "Vali Label:  (2032, 4)\n",
      "Test Data:  (3041, 9000, 1)\n",
      "Test Label:  (3041, 4)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv1D, MaxPooling1D, AveragePooling1D, Dropout\n",
    "from keras.layers import BatchNormalization, Activation\n",
    "from keras.initializers import VarianceScaling\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils, multi_gpu_model\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import TensorBoard, EarlyStopping\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "trainD = np.load(\"/home/hsiehch/30s/train_data.npy\")\n",
    "trainL = np.load(\"/home/hsiehch/30s/train_label.npy\")\n",
    "validationD = np.load(\"/home/hsiehch/30s/validation_data.npy\")\n",
    "validationL = np.load(\"/home/hsiehch/30s/validation_label.npy\")\n",
    "testD = np.load(\"/home/hsiehch/30s/test_data.npy\")\n",
    "testL = np.load(\"/home/hsiehch/30s/test_label.npy\")\n",
    "\n",
    "trainData = trainD.reshape((trainD.shape[0], trainD.shape[1], 1))\n",
    "trainLabel = np_utils.to_categorical(trainL, 4)\n",
    "validationData = validationD.reshape((validationD.shape[0], validationD.shape[1], 1))\n",
    "validationLabel = np_utils.to_categorical(validationL, 4)\n",
    "testData = testD.reshape((testD.shape[0], testD.shape[1], 1))\n",
    "testLabel = np_utils.to_categorical(testL, 4)\n",
    "print('Train Data:', trainData.shape)\n",
    "print('Train Label: ', trainLabel.shape)\n",
    "print('Vali Data: ', validationData.shape)\n",
    "print('Vali Label: ', validationLabel.shape)\n",
    "print('Test Data: ', testData.shape)\n",
    "print('Test Label: ', testLabel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-16T14:33:32.818896Z",
     "start_time": "2018-10-16T14:33:32.804328Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 452.,  150., 2980., 1496.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(trainLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-16T14:56:48.191906Z",
     "start_time": "2018-10-16T14:50:15.593623Z"
    },
    "hide_input": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data: (5078, 9000, 1)\n",
      "Train Label:  (5078, 4)\n",
      "Vali Data:  (2032, 9000, 1)\n",
      "Vali Label:  (2032, 4)\n",
      "Test Data:  (3041, 9000, 1)\n",
      "Test Label:  (3041, 4)\n",
      "Good to go!\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 8994, 32)          256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 8994, 32)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 8994, 32)          128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 4497, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 4491, 32)          7200      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 4491, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 2245, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 2239, 64)          14400     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 2239, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 1119, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 1117, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1117, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 558, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 556, 128)          24704     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 556, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 278, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 276, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 276, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 138, 128)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 138, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 136, 256)          98560     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 136, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 68, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 66, 256)           196864    \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 66, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 33, 256)           0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 33, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 31, 512)           393728    \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 31, 512)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 15, 512)           0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 15, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 13, 512)           786944    \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 13, 512)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6656)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               852096    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 2,440,772\n",
      "Trainable params: 2,440,708\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 5078 samples, validate on 2032 samples\n",
      "Epoch 1/150\n",
      "5078/5078 [==============================] - 10s 2ms/step - loss: 1.0279 - acc: 0.5689 - val_loss: 0.9754 - val_acc: 0.5866\n",
      "Epoch 2/150\n",
      "5078/5078 [==============================] - 5s 932us/step - loss: 0.9307 - acc: 0.5888 - val_loss: 0.9716 - val_acc: 0.6102\n",
      "Epoch 3/150\n",
      "5078/5078 [==============================] - 5s 981us/step - loss: 0.8797 - acc: 0.6225 - val_loss: 1.0038 - val_acc: 0.6304\n",
      "Epoch 4/150\n",
      "5078/5078 [==============================] - 5s 958us/step - loss: 0.7763 - acc: 0.6717 - val_loss: 0.7624 - val_acc: 0.7106\n",
      "Epoch 5/150\n",
      "5078/5078 [==============================] - 5s 940us/step - loss: 0.7079 - acc: 0.7125 - val_loss: 0.7305 - val_acc: 0.6806\n",
      "Epoch 6/150\n",
      "5078/5078 [==============================] - 5s 915us/step - loss: 0.6760 - acc: 0.7213 - val_loss: 0.7538 - val_acc: 0.7234\n",
      "Epoch 7/150\n",
      "5078/5078 [==============================] - 5s 948us/step - loss: 0.6415 - acc: 0.7485 - val_loss: 0.6475 - val_acc: 0.7308\n",
      "Epoch 8/150\n",
      "5078/5078 [==============================] - 5s 949us/step - loss: 0.6351 - acc: 0.7509 - val_loss: 0.6071 - val_acc: 0.7594\n",
      "Epoch 9/150\n",
      "5078/5078 [==============================] - 5s 954us/step - loss: 0.5982 - acc: 0.7631 - val_loss: 0.5827 - val_acc: 0.7564\n",
      "Epoch 10/150\n",
      "5078/5078 [==============================] - 5s 938us/step - loss: 0.5933 - acc: 0.7714 - val_loss: 0.6021 - val_acc: 0.7564\n",
      "Epoch 11/150\n",
      "5078/5078 [==============================] - 5s 911us/step - loss: 0.5723 - acc: 0.7832 - val_loss: 0.5384 - val_acc: 0.7864\n",
      "Epoch 12/150\n",
      "5078/5078 [==============================] - 5s 950us/step - loss: 0.5436 - acc: 0.8015 - val_loss: 0.5549 - val_acc: 0.7913\n",
      "Epoch 13/150\n",
      "5078/5078 [==============================] - 5s 949us/step - loss: 0.5389 - acc: 0.7966 - val_loss: 0.5456 - val_acc: 0.7790\n",
      "Epoch 14/150\n",
      "5078/5078 [==============================] - 5s 939us/step - loss: 0.5448 - acc: 0.7893 - val_loss: 0.5489 - val_acc: 0.7933\n",
      "Epoch 15/150\n",
      "5078/5078 [==============================] - 5s 920us/step - loss: 0.5203 - acc: 0.8027 - val_loss: 0.5519 - val_acc: 0.7795\n",
      "Epoch 16/150\n",
      "5078/5078 [==============================] - 4s 872us/step - loss: 0.5082 - acc: 0.8068 - val_loss: 0.5315 - val_acc: 0.7894\n",
      "Epoch 17/150\n",
      "5078/5078 [==============================] - 5s 922us/step - loss: 0.4853 - acc: 0.8180 - val_loss: 0.5165 - val_acc: 0.8027\n",
      "Epoch 18/150\n",
      "5078/5078 [==============================] - 5s 895us/step - loss: 0.4807 - acc: 0.8200 - val_loss: 0.5335 - val_acc: 0.7938\n",
      "Epoch 19/150\n",
      "5078/5078 [==============================] - 5s 902us/step - loss: 0.4687 - acc: 0.8295 - val_loss: 0.5058 - val_acc: 0.8110\n",
      "Epoch 20/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5078/5078 [==============================] - 5s 937us/step - loss: 0.4489 - acc: 0.8352 - val_loss: 0.4960 - val_acc: 0.8155\n",
      "Epoch 21/150\n",
      "5078/5078 [==============================] - 5s 920us/step - loss: 0.4400 - acc: 0.8417 - val_loss: 0.5022 - val_acc: 0.8076\n",
      "Epoch 22/150\n",
      "5078/5078 [==============================] - 5s 936us/step - loss: 0.4457 - acc: 0.8334 - val_loss: 0.4933 - val_acc: 0.8214\n",
      "Epoch 23/150\n",
      "5078/5078 [==============================] - 5s 928us/step - loss: 0.4327 - acc: 0.8405 - val_loss: 0.5263 - val_acc: 0.8061\n",
      "Epoch 24/150\n",
      "5078/5078 [==============================] - 5s 911us/step - loss: 0.4350 - acc: 0.8438 - val_loss: 0.5101 - val_acc: 0.8258\n",
      "Epoch 25/150\n",
      "5078/5078 [==============================] - 5s 921us/step - loss: 0.4191 - acc: 0.8513 - val_loss: 0.5621 - val_acc: 0.8061\n",
      "Epoch 26/150\n",
      "5078/5078 [==============================] - 4s 886us/step - loss: 0.4104 - acc: 0.8509 - val_loss: 0.4991 - val_acc: 0.8184\n",
      "Epoch 27/150\n",
      "5078/5078 [==============================] - 5s 923us/step - loss: 0.4176 - acc: 0.8482 - val_loss: 0.5560 - val_acc: 0.8115\n",
      "Epoch 28/150\n",
      "5078/5078 [==============================] - 5s 898us/step - loss: 0.4139 - acc: 0.8505 - val_loss: 0.5161 - val_acc: 0.7992\n",
      "Epoch 29/150\n",
      "5078/5078 [==============================] - 4s 886us/step - loss: 0.3895 - acc: 0.8594 - val_loss: 0.4874 - val_acc: 0.8219\n",
      "Epoch 30/150\n",
      "5078/5078 [==============================] - 5s 937us/step - loss: 0.4010 - acc: 0.8566 - val_loss: 0.4991 - val_acc: 0.8248\n",
      "Epoch 31/150\n",
      "5078/5078 [==============================] - 4s 886us/step - loss: 0.3807 - acc: 0.8625 - val_loss: 0.5041 - val_acc: 0.8155\n",
      "Epoch 32/150\n",
      "5078/5078 [==============================] - 5s 915us/step - loss: 0.3833 - acc: 0.8663 - val_loss: 0.5739 - val_acc: 0.7987\n",
      "Epoch 33/150\n",
      "5078/5078 [==============================] - 5s 902us/step - loss: 0.3851 - acc: 0.8655 - val_loss: 0.5546 - val_acc: 0.8135\n",
      "Epoch 34/150\n",
      "5078/5078 [==============================] - 5s 897us/step - loss: 0.3677 - acc: 0.8694 - val_loss: 0.5133 - val_acc: 0.8135\n",
      "Epoch 35/150\n",
      "5078/5078 [==============================] - 5s 922us/step - loss: 0.3761 - acc: 0.8602 - val_loss: 0.5496 - val_acc: 0.8027\n",
      "Epoch 36/150\n",
      "5078/5078 [==============================] - 5s 903us/step - loss: 0.3579 - acc: 0.8706 - val_loss: 0.5388 - val_acc: 0.8287\n",
      "Epoch 37/150\n",
      "5078/5078 [==============================] - 5s 933us/step - loss: 0.3556 - acc: 0.8740 - val_loss: 0.5323 - val_acc: 0.8189\n",
      "Epoch 38/150\n",
      "5078/5078 [==============================] - 5s 892us/step - loss: 0.3490 - acc: 0.8744 - val_loss: 0.5668 - val_acc: 0.8155\n",
      "Epoch 39/150\n",
      "5078/5078 [==============================] - 5s 914us/step - loss: 0.3548 - acc: 0.8714 - val_loss: 0.5276 - val_acc: 0.8238\n",
      "Epoch 40/150\n",
      "5078/5078 [==============================] - 5s 909us/step - loss: 0.3306 - acc: 0.8820 - val_loss: 0.5323 - val_acc: 0.8140\n",
      "Epoch 41/150\n",
      "5078/5078 [==============================] - 5s 919us/step - loss: 0.3360 - acc: 0.8773 - val_loss: 0.5611 - val_acc: 0.8174\n",
      "Epoch 42/150\n",
      "5078/5078 [==============================] - 5s 887us/step - loss: 0.3410 - acc: 0.8769 - val_loss: 0.5393 - val_acc: 0.8278\n",
      "Epoch 43/150\n",
      "5078/5078 [==============================] - 4s 879us/step - loss: 0.3194 - acc: 0.8858 - val_loss: 0.5070 - val_acc: 0.8327\n",
      "Epoch 44/150\n",
      "5078/5078 [==============================] - 5s 923us/step - loss: 0.3199 - acc: 0.8820 - val_loss: 0.5353 - val_acc: 0.8342\n",
      "Epoch 45/150\n",
      "5078/5078 [==============================] - 5s 920us/step - loss: 0.3126 - acc: 0.8852 - val_loss: 0.5503 - val_acc: 0.8184\n",
      "Epoch 46/150\n",
      "5078/5078 [==============================] - 5s 908us/step - loss: 0.3092 - acc: 0.8881 - val_loss: 0.5495 - val_acc: 0.8174\n",
      "Epoch 47/150\n",
      "5078/5078 [==============================] - 5s 926us/step - loss: 0.3205 - acc: 0.8852 - val_loss: 0.5611 - val_acc: 0.8017\n",
      "Epoch 48/150\n",
      "5078/5078 [==============================] - 5s 919us/step - loss: 0.3113 - acc: 0.8897 - val_loss: 0.5639 - val_acc: 0.8179\n",
      "Epoch 49/150\n",
      "5078/5078 [==============================] - 5s 929us/step - loss: 0.3144 - acc: 0.8895 - val_loss: 0.5834 - val_acc: 0.8179\n",
      "Epoch 50/150\n",
      "5078/5078 [==============================] - 5s 895us/step - loss: 0.3156 - acc: 0.8844 - val_loss: 0.5238 - val_acc: 0.8233\n",
      "Epoch 51/150\n",
      "5078/5078 [==============================] - 5s 933us/step - loss: 0.3021 - acc: 0.8944 - val_loss: 0.5327 - val_acc: 0.8219\n",
      "Epoch 52/150\n",
      "5078/5078 [==============================] - 5s 904us/step - loss: 0.2928 - acc: 0.8974 - val_loss: 0.6682 - val_acc: 0.8066\n",
      "Epoch 53/150\n",
      "5078/5078 [==============================] - 5s 914us/step - loss: 0.2842 - acc: 0.8946 - val_loss: 0.5675 - val_acc: 0.8169\n",
      "Epoch 54/150\n",
      "5078/5078 [==============================] - 4s 882us/step - loss: 0.2849 - acc: 0.8946 - val_loss: 0.5939 - val_acc: 0.8100\n",
      "Epoch 55/150\n",
      "5078/5078 [==============================] - 5s 935us/step - loss: 0.2810 - acc: 0.8952 - val_loss: 0.5470 - val_acc: 0.8199\n",
      "Epoch 56/150\n",
      "5078/5078 [==============================] - 5s 905us/step - loss: 0.2813 - acc: 0.9011 - val_loss: 0.5626 - val_acc: 0.8179\n",
      "Epoch 57/150\n",
      "5078/5078 [==============================] - 5s 929us/step - loss: 0.2705 - acc: 0.9049 - val_loss: 0.5879 - val_acc: 0.8199\n",
      "Epoch 58/150\n",
      "5078/5078 [==============================] - 5s 891us/step - loss: 0.2631 - acc: 0.9057 - val_loss: 0.5923 - val_acc: 0.8169\n",
      "Epoch 59/150\n",
      "5078/5078 [==============================] - 5s 942us/step - loss: 0.2730 - acc: 0.9035 - val_loss: 0.5612 - val_acc: 0.8248\n",
      "Epoch 60/150\n",
      "5078/5078 [==============================] - 5s 941us/step - loss: 0.2460 - acc: 0.9135 - val_loss: 0.5829 - val_acc: 0.8233\n",
      "Epoch 61/150\n",
      "5078/5078 [==============================] - 5s 920us/step - loss: 0.2652 - acc: 0.9104 - val_loss: 0.6144 - val_acc: 0.8184\n",
      "Epoch 62/150\n",
      "5078/5078 [==============================] - 5s 907us/step - loss: 0.2496 - acc: 0.9104 - val_loss: 0.5829 - val_acc: 0.8199\n",
      "Epoch 63/150\n",
      "5078/5078 [==============================] - 5s 910us/step - loss: 0.2731 - acc: 0.9015 - val_loss: 0.5517 - val_acc: 0.8253\n",
      "Epoch 64/150\n",
      "5078/5078 [==============================] - 5s 924us/step - loss: 0.2731 - acc: 0.9029 - val_loss: 0.5458 - val_acc: 0.8312\n",
      "Epoch 65/150\n",
      "5078/5078 [==============================] - 5s 903us/step - loss: 0.2529 - acc: 0.9047 - val_loss: 0.5386 - val_acc: 0.8273\n",
      "Epoch 66/150\n",
      "5078/5078 [==============================] - 5s 941us/step - loss: 0.2480 - acc: 0.9027 - val_loss: 0.6363 - val_acc: 0.8243\n",
      "Epoch 67/150\n",
      "5078/5078 [==============================] - 5s 898us/step - loss: 0.2621 - acc: 0.9067 - val_loss: 0.5719 - val_acc: 0.8268\n",
      "Epoch 68/150\n",
      "5078/5078 [==============================] - 5s 920us/step - loss: 0.2291 - acc: 0.9159 - val_loss: 0.5989 - val_acc: 0.8322\n",
      "Epoch 69/150\n",
      "5078/5078 [==============================] - 5s 901us/step - loss: 0.2458 - acc: 0.9118 - val_loss: 0.5873 - val_acc: 0.8174\n",
      "Epoch 70/150\n",
      "5078/5078 [==============================] - 5s 919us/step - loss: 0.2534 - acc: 0.9057 - val_loss: 0.6444 - val_acc: 0.8120\n",
      "Epoch 71/150\n",
      "5078/5078 [==============================] - 5s 900us/step - loss: 0.2440 - acc: 0.9147 - val_loss: 0.5875 - val_acc: 0.8243\n",
      "Epoch 72/150\n",
      "5078/5078 [==============================] - 5s 900us/step - loss: 0.2366 - acc: 0.9147 - val_loss: 0.5712 - val_acc: 0.8223\n",
      "Epoch 73/150\n",
      "5078/5078 [==============================] - 5s 921us/step - loss: 0.2444 - acc: 0.9130 - val_loss: 0.6103 - val_acc: 0.8189\n",
      "Epoch 74/150\n",
      "5078/5078 [==============================] - 4s 883us/step - loss: 0.2169 - acc: 0.9240 - val_loss: 0.5687 - val_acc: 0.8337\n",
      "Epoch 75/150\n",
      "5078/5078 [==============================] - 5s 926us/step - loss: 0.2238 - acc: 0.9185 - val_loss: 0.5874 - val_acc: 0.8248\n",
      "Epoch 76/150\n",
      "5078/5078 [==============================] - 5s 898us/step - loss: 0.2557 - acc: 0.9102 - val_loss: 0.5651 - val_acc: 0.8238\n",
      "Epoch 77/150\n",
      "5078/5078 [==============================] - 5s 908us/step - loss: 0.2204 - acc: 0.9252 - val_loss: 0.6300 - val_acc: 0.8036\n",
      "Epoch 78/150\n",
      "5078/5078 [==============================] - 5s 909us/step - loss: 0.2286 - acc: 0.9189 - val_loss: 0.6778 - val_acc: 0.8258\n",
      "Epoch 79/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5078/5078 [==============================] - 4s 883us/step - loss: 0.2203 - acc: 0.9222 - val_loss: 0.5877 - val_acc: 0.8164\n",
      "Epoch 80/150\n",
      "5078/5078 [==============================] - 5s 898us/step - loss: 0.2271 - acc: 0.9193 - val_loss: 0.6351 - val_acc: 0.8287\n",
      "Epoch 81/150\n",
      "5078/5078 [==============================] - 5s 928us/step - loss: 0.2223 - acc: 0.9228 - val_loss: 0.6051 - val_acc: 0.8238\n",
      "Epoch 82/150\n",
      "5078/5078 [==============================] - 5s 893us/step - loss: 0.1953 - acc: 0.9293 - val_loss: 0.6812 - val_acc: 0.8297\n",
      "Epoch 83/150\n",
      "1190/5078 [======>.......................] - ETA: 3s - loss: 0.2134 - acc: 0.9193"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-21f14cf8f281>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    115\u001b[0m                             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                             verbose=1)\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;31m# model.save('model_30s.h5')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    963\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1667\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1669\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1204\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1206\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1207\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv1D, MaxPooling1D, AveragePooling1D, Dropout\n",
    "from keras.layers import BatchNormalization, Activation\n",
    "from keras.initializers import VarianceScaling\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils, multi_gpu_model\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import TensorBoard, EarlyStopping\n",
    "from sklearn.utils import class_weight\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "trainD = np.load(\"/home/hsiehch/30s/train_data.npy\")\n",
    "trainL = np.load(\"/home/hsiehch/30s/train_label.npy\")\n",
    "validationD = np.load(\"/home/hsiehch/30s/validation_data.npy\")\n",
    "validationL = np.load(\"/home/hsiehch/30s/validation_label.npy\")\n",
    "testD = np.load(\"/home/hsiehch/30s/test_data.npy\")\n",
    "testL = np.load(\"/home/hsiehch/30s/test_label.npy\")\n",
    "\n",
    "trainData = trainD.reshape((trainD.shape[0], trainD.shape[1], 1))\n",
    "trainLabel = np_utils.to_categorical(trainL, 4)\n",
    "validationData = validationD.reshape((validationD.shape[0], validationD.shape[1], 1))\n",
    "validationLabel = np_utils.to_categorical(validationL, 4)\n",
    "testData = testD.reshape((testD.shape[0], testD.shape[1], 1))\n",
    "testLabel = np_utils.to_categorical(testL, 4)\n",
    "print('Train Data:', trainData.shape)\n",
    "print('Train Label: ', trainLabel.shape)\n",
    "print('Vali Data: ', validationData.shape)\n",
    "print('Vali Label: ', validationLabel.shape)\n",
    "print('Test Data: ', testData.shape)\n",
    "print('Test Label: ', testLabel.shape)\n",
    "\n",
    "\n",
    "try:\n",
    "    model and parallel_model\n",
    "except NameError:\n",
    "    print(\"Good to go!\")\n",
    "    pass\n",
    "else:   \n",
    "    if model:\n",
    "        del model\n",
    "        del parallel_model\n",
    "    print(\"Object has been cleaned!\")\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters = 32, kernel_size = 7, input_shape = (trainData.shape[1], 1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size = 2))\n",
    "\n",
    "model.add(Conv1D(filters = 32, kernel_size = 7))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size = 2))\n",
    "\n",
    "model.add(Conv1D(filters = 64, kernel_size = 7))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size = 2))\n",
    "\n",
    "model.add(Conv1D(filters = 64, kernel_size = 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size = 2))\n",
    "\n",
    "model.add(Conv1D(filters = 128, kernel_size = 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size = 2))\n",
    "\n",
    "model.add(Conv1D(filters = 128, kernel_size = 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size = 2))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv1D(filters = 256, kernel_size = 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size = 2))\n",
    "\n",
    "model.add(Conv1D(filters = 256, kernel_size = 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size = 2))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv1D(filters = 512, kernel_size = 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size = 2))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv1D(filters = 512, kernel_size = 3))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32, activation = 'relu'))\n",
    "model.add(Dense(4, activation = \"softmax\"))\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "adam = Adam(lr = 0.001)\n",
    "model.compile(optimizer = adam, loss = \"categorical_crossentropy\", metrics=['accuracy'])\n",
    "\n",
    "# class_weight = {0: 7.,\n",
    "#                 1: 20.,\n",
    "#                 2: 1.,\n",
    "#                 3: 2.}\n",
    "class_weight = class_weight.compute_sample_weight('balanced', [0,1,2,3], trainL)\n",
    "# early_stop = EarlyStopping(patience=20)\n",
    "train_history_1 = model.fit(x = trainData,\n",
    "                            y = trainLabel,\n",
    "                            epochs=150,\n",
    "                            validation_data=(validationData, validationLabel),\n",
    "#                             callbacks=[early_stop],\n",
    "                            class_weight=class_weight,\n",
    "                            batch_size=70, \n",
    "                            verbose=1)\n",
    "# model.save('model_30s.h5')\n",
    "\n",
    "evaluation = model.evaluate(x = testData, y = testLabel)\n",
    "print('Loss: {:.3f}, Accuracy: {:.3f}'.format(evaluation[0], evaluation[1]))\n",
    "\n",
    "\n",
    "print('Finish training!')\n",
    "\n",
    "import pylab as plt\n",
    "def history_display(hist, train, validation):\n",
    "    plt.plot(hist.history[train])\n",
    "    plt.plot(hist.history[validation])\n",
    "    plt.title('Train History')\n",
    "    plt.ylabel(train)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show\n",
    "    \n",
    "def show_plot(flag, hist):\n",
    "    if flag == 'acc':\n",
    "        history_display(hist, 'acc', 'val_acc')\n",
    "    elif flag == 'loss':\n",
    "        history_display(hist, 'loss', 'val_loss')\n",
    "    else:\n",
    "        print('Invalid!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T09:52:47.682228Z",
     "start_time": "2018-09-05T09:52:46.090800Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[array([[[-0.17479362,  0.2614714 ,  0.03239799, ...,  0.01125135,\n",
      "         -0.07346149, -0.24756096],\n",
      "        [-0.24847883,  0.27277437,  0.03623412, ..., -0.01803227,\n",
      "         -0.13194561, -0.17802595],\n",
      "        [-0.3409852 ,  0.27115685, -0.03087586, ..., -0.13087817,\n",
      "         -0.00664551, -0.14448875],\n",
      "        ...,\n",
      "        [-0.12818672,  0.09765437, -0.10548794, ..., -0.02726372,\n",
      "         -0.00115754, -0.02225547],\n",
      "        [-0.08185092,  0.07402135, -0.03721559, ...,  0.02435363,\n",
      "         -0.08601385, -0.16661033],\n",
      "        [-0.13652857,  0.25169188,  0.09609877, ...,  0.01470644,\n",
      "         -0.01689167, -0.16806498]]], dtype=float32)],\n",
      " [array([[[0.        , 0.2614714 , 0.03239799, ..., 0.01125135,\n",
      "         0.        , 0.        ],\n",
      "        [0.        , 0.27277437, 0.03623412, ..., 0.        ,\n",
      "         0.        , 0.        ],\n",
      "        [0.        , 0.27115685, 0.        , ..., 0.        ,\n",
      "         0.        , 0.        ],\n",
      "        ...,\n",
      "        [0.        , 0.09765437, 0.        , ..., 0.        ,\n",
      "         0.        , 0.        ],\n",
      "        [0.        , 0.07402135, 0.        , ..., 0.02435363,\n",
      "         0.        , 0.        ],\n",
      "        [0.        , 0.25169188, 0.09609877, ..., 0.01470644,\n",
      "         0.        , 0.        ]]], dtype=float32)],\n",
      " [array([[[-0.3970949 ,  3.1726265 ,  0.69544613, ..., -0.57587373,\n",
      "         -0.6816484 , -0.09777778],\n",
      "        [-0.3970949 ,  3.3428736 ,  0.80400956, ..., -0.91109335,\n",
      "         -0.6816484 , -0.09777778],\n",
      "        [-0.3970949 ,  3.31851   , -0.22142313, ..., -0.91109335,\n",
      "         -0.6816484 , -0.09777778],\n",
      "        ...,\n",
      "        [-0.3970949 ,  0.7051921 , -0.22142313, ..., -0.91109335,\n",
      "         -0.6816484 , -0.09777778],\n",
      "        [-0.3970949 ,  0.34922838, -0.22142313, ..., -0.18550783,\n",
      "         -0.6816484 , -0.09777778],\n",
      "        [-0.3970949 ,  3.0253263 ,  2.4981906 , ..., -0.4729337 ,\n",
      "         -0.6816484 , -0.09777778]]], dtype=float32)],\n",
      " [array([[[-0.3970949 ,  3.3428736 ,  0.80400956, ..., -0.57587373,\n",
      "         -0.6816484 , -0.09777778],\n",
      "        [-0.3970949 ,  3.31851   , -0.22142313, ...,  0.8948667 ,\n",
      "         -0.6816484 , -0.09777778],\n",
      "        [-0.1945895 ,  1.5401384 , -0.22142313, ...,  6.0191603 ,\n",
      "         -0.6816484 , -0.09777778],\n",
      "        ...,\n",
      "        [-0.3970949 ,  1.5086614 ,  0.21079145, ...,  0.4268887 ,\n",
      "         -0.6816484 , -0.09777778],\n",
      "        [-0.3970949 ,  2.247064  ,  1.0634316 , ...,  1.5115181 ,\n",
      "         -0.6816484 , -0.09777778],\n",
      "        [-0.3970949 ,  3.0253263 ,  2.4981906 , ..., -0.18550783,\n",
      "         -0.6816484 , -0.09777778]]], dtype=float32)],\n",
      " [array([[[ 4.6911    , -3.313371  , -7.506126  , ..., -4.283003  ,\n",
      "          0.6896061 ,  1.0525949 ],\n",
      "        [ 2.4020786 ,  0.9767452 , -7.0245748 , ..., -3.2817075 ,\n",
      "          2.701989  , -0.15438397],\n",
      "        [ 5.6504893 , -2.447743  , -6.943911  , ..., -4.0876102 ,\n",
      "          2.0447226 ,  3.7687206 ],\n",
      "        ...,\n",
      "        [ 3.6394436 , -0.5614933 , -4.4633226 , ..., -2.474375  ,\n",
      "          1.0906928 ,  2.3443    ],\n",
      "        [ 3.7027051 , -2.405633  , -4.96192   , ..., -2.3928227 ,\n",
      "          0.38140565,  2.6425922 ],\n",
      "        [ 3.4638412 , -1.4499364 , -4.0320535 , ..., -2.11568   ,\n",
      "          2.5985076 ,  1.5673703 ]]], dtype=float32)],\n",
      " [array([[[4.6911    , 0.        , 0.        , ..., 0.        ,\n",
      "         0.6896061 , 1.0525949 ],\n",
      "        [2.4020786 , 0.9767452 , 0.        , ..., 0.        ,\n",
      "         2.701989  , 0.        ],\n",
      "        [5.6504893 , 0.        , 0.        , ..., 0.        ,\n",
      "         2.0447226 , 3.7687206 ],\n",
      "        ...,\n",
      "        [3.6394436 , 0.        , 0.        , ..., 0.        ,\n",
      "         1.0906928 , 2.3443    ],\n",
      "        [3.7027051 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.38140565, 2.6425922 ],\n",
      "        [3.4638412 , 0.        , 0.        , ..., 0.        ,\n",
      "         2.5985076 , 1.5673703 ]]], dtype=float32)],\n",
      " [array([[[4.6911    , 0.9767452 , 0.        , ..., 0.        ,\n",
      "         2.701989  , 1.0525949 ],\n",
      "        [5.6504893 , 0.        , 0.        , ..., 0.        ,\n",
      "         2.0447226 , 3.7687206 ],\n",
      "        [3.3940563 , 1.5354079 , 0.        , ..., 0.        ,\n",
      "         3.5065453 , 2.96272   ],\n",
      "        ...,\n",
      "        [4.765681  , 0.        , 0.        , ..., 0.        ,\n",
      "         4.626261  , 3.816783  ],\n",
      "        [4.182479  , 0.08914938, 0.        , ..., 0.        ,\n",
      "         2.3620887 , 3.2643986 ],\n",
      "        [3.7027051 , 0.        , 0.        , ..., 0.        ,\n",
      "         1.0906928 , 2.6425922 ]]], dtype=float32)],\n",
      " [array([[[-0.9317915 , -0.11048548, -3.3290346 , ..., -6.7475233 ,\n",
      "         -6.252215  , -3.439399  ],\n",
      "        [-2.1420465 , -0.69621855, -1.904064  , ..., -5.2005677 ,\n",
      "         -4.2989755 , -3.839784  ],\n",
      "        [-0.9940501 , -0.92269474, -2.7197764 , ..., -5.028676  ,\n",
      "         -4.6993065 , -4.069913  ],\n",
      "        ...,\n",
      "        [ 0.05601242, -1.3235266 , -2.5226188 , ..., -6.2307024 ,\n",
      "         -4.6910057 , -3.7308614 ],\n",
      "        [-1.7147065 ,  0.5845696 , -1.7553144 , ..., -6.2550855 ,\n",
      "         -3.9331052 , -3.8649578 ],\n",
      "        [-1.5245078 , -0.47442967, -4.179132  , ..., -6.7422132 ,\n",
      "         -4.697146  , -3.9603899 ]]], dtype=float32)],\n",
      " [array([[[0.        , 0.        , 0.        , ..., 0.        ,\n",
      "         0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "         0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "         0.        , 0.        ],\n",
      "        ...,\n",
      "        [0.05601242, 0.        , 0.        , ..., 0.        ,\n",
      "         0.        , 0.        ],\n",
      "        [0.        , 0.5845696 , 0.        , ..., 0.        ,\n",
      "         0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "         0.        , 0.        ]]], dtype=float32)],\n",
      " [array([[[0.        , 0.        , 0.        , ..., 0.        ,\n",
      "         0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "         0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "         0.        , 0.        ],\n",
      "        ...,\n",
      "        [0.04158197, 0.        , 0.        , ..., 0.        ,\n",
      "         0.        , 0.        ],\n",
      "        [0.        , 0.29232123, 0.        , ..., 0.        ,\n",
      "         0.        , 0.        ],\n",
      "        [0.05601242, 0.5845696 , 0.        , ..., 0.        ,\n",
      "         0.        , 0.        ]]], dtype=float32)],\n",
      " [array([[[ 0.5933738 , -1.425639  , -0.6634584 , ..., -1.0281749 ,\n",
      "          0.06114398, -1.9607579 ],\n",
      "        [ 0.9735015 , -1.8784473 , -0.64034957, ..., -0.6986883 ,\n",
      "          0.07230978, -2.1946542 ],\n",
      "        [ 1.0089077 , -1.4959335 , -0.4205349 , ..., -0.59250444,\n",
      "         -0.16688804, -2.2131171 ],\n",
      "        ...,\n",
      "        [-0.03072119, -1.2422241 , -1.1355304 , ..., -0.89085037,\n",
      "          0.12682255, -2.1024902 ],\n",
      "        [ 0.53866464, -2.1612637 , -0.8951064 , ..., -1.6217059 ,\n",
      "         -0.17590795, -2.1545303 ],\n",
      "        [ 0.3470922 , -1.6359708 , -0.5449726 , ..., -0.886736  ,\n",
      "         -0.28438026, -2.4236293 ]]], dtype=float32)],\n",
      " [array([[[0.5933738 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.06114398, 0.        ],\n",
      "        [0.9735015 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.07230978, 0.        ],\n",
      "        [1.0089077 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.        , 0.        ],\n",
      "        ...,\n",
      "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "         0.12682255, 0.        ],\n",
      "        [0.53866464, 0.        , 0.        , ..., 0.        ,\n",
      "         0.        , 0.        ],\n",
      "        [0.3470922 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.        , 0.        ]]], dtype=float32)],\n",
      " [array([[[0.9735015 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.07230978, 0.        ],\n",
      "        [1.0089077 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.        , 0.        ],\n",
      "        [0.98823196, 0.        , 0.        , ..., 0.        ,\n",
      "         0.40110004, 0.        ],\n",
      "        ...,\n",
      "        [1.1319599 , 0.        , 0.        , ..., 0.        ,\n",
      "         0.26483542, 0.        ],\n",
      "        [0.44552243, 0.        , 0.        , ..., 0.        ,\n",
      "         0.        , 0.        ],\n",
      "        [0.53866464, 0.        , 0.        , ..., 0.        ,\n",
      "         0.12682255, 0.        ]]], dtype=float32)],\n",
      " [array([[[-0.7747013 , -0.06307393, -0.58884573, ..., -0.48659495,\n",
      "         -1.0984958 , -0.65003866],\n",
      "        [-0.75481623,  0.04672903, -0.6579293 , ..., -0.381762  ,\n",
      "         -1.1017429 , -0.57825977],\n",
      "        [-0.72947085, -0.00804445, -0.65830165, ..., -0.5815812 ,\n",
      "         -1.334228  , -0.52774614],\n",
      "        ...,\n",
      "        [-0.7564527 , -0.06566546, -0.5710782 , ..., -0.62922174,\n",
      "         -1.116805  , -0.79508895],\n",
      "        [-0.5812463 , -0.05028188, -0.7778493 , ..., -0.59824145,\n",
      "         -1.1953022 , -0.6758561 ],\n",
      "        [-0.58660287, -0.09138343, -0.62624484, ..., -0.5943932 ,\n",
      "         -0.9024984 , -0.70231324]]], dtype=float32)],\n",
      " [array([[[0.        , 0.        , 0.        , ..., 0.        ,\n",
      "         0.        , 0.        ],\n",
      "        [0.        , 0.04672903, 0.        , ..., 0.        ,\n",
      "         0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "         0.        , 0.        ],\n",
      "        ...,\n",
      "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "         0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "         0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "         0.        , 0.        ]]], dtype=float32)],\n",
      " [array([[[0.        , 0.04672903, 0.        , ..., 0.        ,\n",
      "         0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "         0.        , 0.        ],\n",
      "        [0.        , 0.13207066, 0.        , ..., 0.        ,\n",
      "         0.        , 0.        ],\n",
      "        ...,\n",
      "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "         0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "         0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "         0.        , 0.        ]]], dtype=float32)],\n",
      " [array([[[-0.06626491, -0.7476025 , -0.7182564 , ..., -1.1245949 ,\n",
      "         -0.72324294, -0.74148947],\n",
      "        [-0.08778559, -0.8575371 , -0.6931729 , ..., -1.1174152 ,\n",
      "         -0.6453571 , -0.579323  ],\n",
      "        [-0.07954341, -0.66816854, -0.69813526, ..., -1.0200117 ,\n",
      "         -0.51579756, -0.5284164 ],\n",
      "        ...,\n",
      "        [-0.00448949, -0.8262062 , -0.6809183 , ..., -1.2073113 ,\n",
      "         -0.6473778 , -0.5921451 ],\n",
      "        [-0.03474842, -0.6535015 , -0.71944505, ..., -1.2306231 ,\n",
      "         -0.5416596 , -0.58121336],\n",
      "        [-0.07429506, -0.71184456, -0.78529334, ..., -1.1517745 ,\n",
      "         -0.58714217, -0.54716414]]], dtype=float32)],\n",
      " [array([[[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)],\n",
      " [array([[[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)],\n",
      " [array([[[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)],\n",
      " [array([[[-0.10652269, -0.13372433,  0.06127495, ...,  0.02823099,\n",
      "         -0.14111304, -0.03386174],\n",
      "        [-0.12439762, -0.14700836,  0.03339041, ...,  0.02218588,\n",
      "         -0.1270771 , -0.05676127],\n",
      "        [-0.11695161, -0.12837705,  0.06510197, ..., -0.00068058,\n",
      "         -0.08523922, -0.01792438],\n",
      "        ...,\n",
      "        [-0.11629691, -0.14568342,  0.03711227, ...,  0.01768908,\n",
      "         -0.15454017, -0.03649771],\n",
      "        [-0.12199717, -0.16352746,  0.05259922, ...,  0.02966516,\n",
      "         -0.1579903 , -0.06606298],\n",
      "        [-0.10878772, -0.12381054,  0.05189298, ...,  0.02666789,\n",
      "         -0.12981568, -0.0122411 ]]], dtype=float32)],\n",
      " [array([[[0.        , 0.        , 0.06127495, ..., 0.02823099,\n",
      "         0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.03339041, ..., 0.02218588,\n",
      "         0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.06510197, ..., 0.        ,\n",
      "         0.        , 0.        ],\n",
      "        ...,\n",
      "        [0.        , 0.        , 0.03711227, ..., 0.01768908,\n",
      "         0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.05259922, ..., 0.02966516,\n",
      "         0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.05189298, ..., 0.02666789,\n",
      "         0.        , 0.        ]]], dtype=float32)],\n",
      " [array([[[0.        , 0.        , 0.06127495, ..., 0.02823099,\n",
      "         0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.06510197, ..., 0.        ,\n",
      "         0.        , 0.01020931],\n",
      "        [0.        , 0.        , 0.06191803, ..., 0.04229942,\n",
      "         0.        , 0.        ],\n",
      "        ...,\n",
      "        [0.        , 0.        , 0.09316213, ..., 0.00899571,\n",
      "         0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.08309272, ..., 0.05090258,\n",
      "         0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.05259922, ..., 0.02966516,\n",
      "         0.        , 0.        ]]], dtype=float32)],\n",
      " [array([[[-0.18911815, -0.20824493, -0.19840571, ..., -0.11263508,\n",
      "         -0.122248  , -0.26401484],\n",
      "        [-0.20993128, -0.2118044 , -0.20431162, ..., -0.11239102,\n",
      "         -0.13574965, -0.2903947 ],\n",
      "        [-0.19042182, -0.20360158, -0.20093876, ..., -0.11636439,\n",
      "         -0.13638844, -0.25803676],\n",
      "        ...,\n",
      "        [-0.22092216, -0.22383577, -0.21035245, ..., -0.11583053,\n",
      "         -0.13766271, -0.3097854 ],\n",
      "        [-0.19404508, -0.23113146, -0.20887971, ..., -0.13098711,\n",
      "         -0.12276492, -0.30159324],\n",
      "        [-0.21634382, -0.20860611, -0.19488907, ..., -0.12696409,\n",
      "         -0.12856984, -0.28890336]]], dtype=float32)],\n",
      " [array([[[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)],\n",
      " [array([[[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)],\n",
      " [array([[[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)],\n",
      " [array([[[-0.16503449, -0.06811692,  0.01209773, ..., -0.04310498,\n",
      "         -0.10320297, -0.07728063],\n",
      "        [-0.16635436, -0.0681448 ,  0.01650184, ..., -0.04101267,\n",
      "         -0.10580979, -0.07623888],\n",
      "        [-0.1687437 , -0.06959741,  0.01384149, ..., -0.04500185,\n",
      "         -0.10587183, -0.07863221],\n",
      "        ...,\n",
      "        [-0.18272994, -0.07698437,  0.01906769, ..., -0.0533874 ,\n",
      "         -0.11367245, -0.0872109 ],\n",
      "        [-0.18100707, -0.07857474,  0.01311363, ..., -0.04864185,\n",
      "         -0.1185791 , -0.08546606],\n",
      "        [-0.18011907, -0.07508438,  0.01347039, ..., -0.04842262,\n",
      "         -0.1139085 , -0.08273463]]], dtype=float32)],\n",
      " [array([[[0.        , 0.        , 0.01209773, ..., 0.        ,\n",
      "         0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.01650184, ..., 0.        ,\n",
      "         0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.01384149, ..., 0.        ,\n",
      "         0.        , 0.        ],\n",
      "        ...,\n",
      "        [0.        , 0.        , 0.01906769, ..., 0.        ,\n",
      "         0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.01311363, ..., 0.        ,\n",
      "         0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.01347039, ..., 0.        ,\n",
      "         0.        , 0.        ]]], dtype=float32)],\n",
      " [array([[[0.        , 0.        , 0.01650184, ..., 0.        ,\n",
      "         0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.01600753, ..., 0.        ,\n",
      "         0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.01271575, ..., 0.        ,\n",
      "         0.        , 0.        ],\n",
      "        ...,\n",
      "        [0.        , 0.        , 0.01907851, ..., 0.        ,\n",
      "         0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.02346526, ..., 0.        ,\n",
      "         0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.01906769, ..., 0.        ,\n",
      "         0.        , 0.        ]]], dtype=float32)],\n",
      " [array([[[0.        , 0.        , 0.01650184, ..., 0.        ,\n",
      "         0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.01600753, ..., 0.        ,\n",
      "         0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.01271575, ..., 0.        ,\n",
      "         0.        , 0.        ],\n",
      "        ...,\n",
      "        [0.        , 0.        , 0.01907851, ..., 0.        ,\n",
      "         0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.02346526, ..., 0.        ,\n",
      "         0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.01906769, ..., 0.        ,\n",
      "         0.        , 0.        ]]], dtype=float32)],\n",
      " [array([[[-0.0282558 , -0.8922488 , -0.29772863, ..., -0.16316244,\n",
      "         -0.15294021, -0.18197902],\n",
      "        [-0.03020616, -0.9140394 , -0.30896538, ..., -0.1660258 ,\n",
      "         -0.15559381, -0.1866663 ],\n",
      "        [-0.03352562, -0.9163013 , -0.31173253, ..., -0.1642312 ,\n",
      "         -0.15572812, -0.17810479],\n",
      "        ...,\n",
      "        [-0.04748397, -0.8763546 , -0.30121806, ..., -0.1620312 ,\n",
      "         -0.15434219, -0.1488559 ],\n",
      "        [-0.03896791, -0.8805727 , -0.29781917, ..., -0.16205227,\n",
      "         -0.15597527, -0.18617855],\n",
      "        [-0.0490769 , -0.90542537, -0.30855218, ..., -0.17008926,\n",
      "         -0.15912795, -0.20200355]]], dtype=float32)],\n",
      " [array([[[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)],\n",
      " [array([[0., 0., 0., ..., 0., 0., 0.]], dtype=float32)],\n",
      " [array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.539429  ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.28529322, 0.        , 0.3805035 , 0.        , 0.        ,\n",
      "        0.18569294, 0.        , 0.        , 0.        , 0.02882676,\n",
      "        0.89921576, 0.        , 0.0419128 , 0.32447612, 0.        ,\n",
      "        0.        , 0.        , 0.4271184 , 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.15255877, 0.80603176, 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.        , 1.0245055 ,\n",
      "        0.        , 0.        , 0.04064895, 0.2181967 , 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.38745615, 0.6280813 ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.449693  ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.27837062,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.16693872, 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.06262483, 0.7178199 , 0.22694221, 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.19070578, 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.28334254,\n",
      "        0.        , 0.        , 0.        , 0.57127005, 0.        ,\n",
      "        0.03687442, 0.        , 0.3567291 , 0.        , 0.        ,\n",
      "        0.16098234, 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.46587768, 0.24872823, 0.        , 0.        , 0.        ,\n",
      "        0.26258433, 0.        , 0.7001468 ]], dtype=float32)],\n",
      " [array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.539429  ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.28529322, 0.        , 0.3805035 , 0.        , 0.        ,\n",
      "        0.18569294, 0.        , 0.        , 0.        , 0.02882676,\n",
      "        0.89921576, 0.        , 0.0419128 , 0.32447612, 0.        ,\n",
      "        0.        , 0.        , 0.4271184 , 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.15255877, 0.80603176, 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.        , 1.0245055 ,\n",
      "        0.        , 0.        , 0.04064895, 0.2181967 , 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.38745615, 0.6280813 ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.449693  ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.27837062,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.16693872, 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.06262483, 0.7178199 , 0.22694221, 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.19070578, 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.28334254,\n",
      "        0.        , 0.        , 0.        , 0.57127005, 0.        ,\n",
      "        0.03687442, 0.        , 0.3567291 , 0.        , 0.        ,\n",
      "        0.16098234, 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.46587768, 0.24872823, 0.        , 0.        , 0.        ,\n",
      "        0.26258433, 0.        , 0.7001468 ]], dtype=float32)],\n",
      " [array([[0.65235376, 0.1970175 , 0.15471847, 0.5542062 , 0.        ,\n",
      "        0.6683745 , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.        , 0.8452327 , 0.        , 0.8836498 ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "        0.        , 0.11709002, 0.13442568, 0.        , 0.        ,\n",
      "        0.        , 1.2607931 , 0.        , 0.31045362, 0.3813809 ,\n",
      "        0.        , 0.        ]], dtype=float32)],\n",
      " [array([[0.1742641 , 0.45011094, 0.11405721, 0.26156774]], dtype=float32)]]\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "import pprint\n",
    "\n",
    "inp = model.input                                           # input placeholder\n",
    "outputs = [layer.output for layer in model.layers]          # all layer outputs\n",
    "functors = [K.function([inp], [out]) for out in outputs]    # evaluation functions\n",
    "\n",
    "# Testing\n",
    "test = np.random.random((trainData.shape[1], 1))[np.newaxis,...]\n",
    "layer_outs = [func([test]) for func in functors]\n",
    "pprint.pprint(layer_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-16T14:57:26.596014Z",
     "start_time": "2018-10-16T14:57:12.315026Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>175</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>55</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1679</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43</td>\n",
       "      <td>5</td>\n",
       "      <td>242</td>\n",
       "      <td>605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "prediction    0   1     2    3\n",
       "Label                         \n",
       "0           175   8    14   73\n",
       "1             5  55    21    8\n",
       "2             5   7  1679   96\n",
       "3            43   5   242  605"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test_prediction = model.predict_classes(testData, batch_size=1)\n",
    "pd.crosstab(testL, test_prediction, rownames=['Label'], colnames=['prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T04:33:32.273567Z",
     "start_time": "2018-07-23T04:33:31.858976Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save('1D_model_30s_early_stopping.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-16T14:57:01.369497Z",
     "start_time": "2018-10-16T14:57:01.349298Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'show_plot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b5f6ee9796eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshow_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_history_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'show_plot' is not defined"
     ]
    }
   ],
   "source": [
    "show_plot('acc', train_history_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T06:21:16.255475Z",
     "start_time": "2018-09-15T06:21:16.047893Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_plot('loss', train_history_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 30s k-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-06T04:51:55.269179Z",
     "start_time": "2018-10-06T04:51:52.446806Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data: (10151, 9000, 1)\n",
      "Train Label:  (10151, 4)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv1D, MaxPooling1D, AveragePooling1D, Dropout\n",
    "from keras.layers import Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import TensorBoard, EarlyStopping\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "trainD = np.load(\"/home/hsiehch/30s/train_data.npy\")\n",
    "trainL = np.load(\"/home/hsiehch/30s/train_label.npy\")\n",
    "validationD = np.load(\"/home/hsiehch/30s/validation_data.npy\")\n",
    "validationL = np.load(\"/home/hsiehch/30s/validation_label.npy\")\n",
    "testD = np.load(\"/home/hsiehch/30s/test_data.npy\")\n",
    "testL = np.load(\"/home/hsiehch/30s/test_label.npy\")\n",
    "\n",
    "trainD = np.append(trainD, validationD, axis=0)\n",
    "trainL = np.append(trainL, validationL, axis=0)\n",
    "trainD = np.append(trainD, testD, axis=0)\n",
    "trainL = np.append(trainL, testL, axis=0)\n",
    "\n",
    "trainData = trainD.reshape((trainD.shape[0], trainD.shape[1], 1))\n",
    "trainLabel = np_utils.to_categorical(trainL, 4)\n",
    "print('Train Data:', trainData.shape)\n",
    "print('Train Label: ', trainLabel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-06T04:53:56.315767Z",
     "start_time": "2018-10-06T04:53:53.336766Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=5, random_state=None, shuffle=True)\n",
      "trian: [    0     1     2 ... 10147 10149 10150] len 8120 test: [   11    29    34 ... 10142 10146 10148] len 2031\n",
      "[[[ 0.519]\n",
      "  [ 0.619]\n",
      "  [ 0.723]\n",
      "  ...\n",
      "  [ 0.116]\n",
      "  [ 0.017]\n",
      "  [ 0.018]]\n",
      "\n",
      " [[-0.188]\n",
      "  [-0.239]\n",
      "  [-0.274]\n",
      "  ...\n",
      "  [-0.077]\n",
      "  [-0.077]\n",
      "  [-0.078]]\n",
      "\n",
      " [[-0.079]\n",
      "  [-0.079]\n",
      "  [-0.079]\n",
      "  ...\n",
      "  [-0.093]\n",
      "  [-0.057]\n",
      "  [ 0.   ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.202]\n",
      "  [-0.235]\n",
      "  [-0.272]\n",
      "  ...\n",
      "  [-0.032]\n",
      "  [-0.023]\n",
      "  [-0.015]]\n",
      "\n",
      " [[-0.227]\n",
      "  [-0.297]\n",
      "  [-0.374]\n",
      "  ...\n",
      "  [-0.054]\n",
      "  [-0.044]\n",
      "  [-0.036]]\n",
      "\n",
      " [[-0.237]\n",
      "  [-0.286]\n",
      "  [-0.338]\n",
      "  ...\n",
      "  [-0.016]\n",
      "  [-0.017]\n",
      "  [-0.018]]]\n",
      "[[[-0.023]\n",
      "  [-0.029]\n",
      "  [-0.038]\n",
      "  ...\n",
      "  [ 0.014]\n",
      "  [ 0.01 ]\n",
      "  [ 0.006]]\n",
      "\n",
      " [[ 0.053]\n",
      "  [ 0.058]\n",
      "  [ 0.061]\n",
      "  ...\n",
      "  [-0.017]\n",
      "  [-0.009]\n",
      "  [-0.006]]\n",
      "\n",
      " [[-0.375]\n",
      "  [-0.454]\n",
      "  [-0.542]\n",
      "  ...\n",
      "  [-0.134]\n",
      "  [-0.111]\n",
      "  [-0.084]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.275]\n",
      "  [ 0.332]\n",
      "  [ 0.388]\n",
      "  ...\n",
      "  [ 0.026]\n",
      "  [ 0.028]\n",
      "  [ 0.03 ]]\n",
      "\n",
      " [[-0.104]\n",
      "  [-0.127]\n",
      "  [-0.144]\n",
      "  ...\n",
      "  [ 0.049]\n",
      "  [ 0.045]\n",
      "  [ 0.035]]\n",
      "\n",
      " [[-0.095]\n",
      "  [-0.095]\n",
      "  [-0.094]\n",
      "  ...\n",
      "  [-0.313]\n",
      "  [-0.173]\n",
      "  [-0.052]]]\n",
      "trian: [    0     2     5 ... 10148 10149 10150] len 8121 test: [    1     3     4 ... 10121 10125 10147] len 2030\n",
      "[[[ 0.519]\n",
      "  [ 0.619]\n",
      "  [ 0.723]\n",
      "  ...\n",
      "  [ 0.116]\n",
      "  [ 0.017]\n",
      "  [ 0.018]]\n",
      "\n",
      " [[-0.079]\n",
      "  [-0.079]\n",
      "  [-0.079]\n",
      "  ...\n",
      "  [-0.093]\n",
      "  [-0.057]\n",
      "  [ 0.   ]]\n",
      "\n",
      " [[-0.39 ]\n",
      "  [-0.462]\n",
      "  [-0.542]\n",
      "  ...\n",
      "  [ 0.016]\n",
      "  [ 0.009]\n",
      "  [ 0.001]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.095]\n",
      "  [-0.095]\n",
      "  [-0.094]\n",
      "  ...\n",
      "  [-0.313]\n",
      "  [-0.173]\n",
      "  [-0.052]]\n",
      "\n",
      " [[-0.227]\n",
      "  [-0.297]\n",
      "  [-0.374]\n",
      "  ...\n",
      "  [-0.054]\n",
      "  [-0.044]\n",
      "  [-0.036]]\n",
      "\n",
      " [[-0.237]\n",
      "  [-0.286]\n",
      "  [-0.338]\n",
      "  ...\n",
      "  [-0.016]\n",
      "  [-0.017]\n",
      "  [-0.018]]]\n",
      "[[[-0.188]\n",
      "  [-0.239]\n",
      "  [-0.274]\n",
      "  ...\n",
      "  [-0.077]\n",
      "  [-0.077]\n",
      "  [-0.078]]\n",
      "\n",
      " [[ 0.051]\n",
      "  [ 0.056]\n",
      "  [ 0.059]\n",
      "  ...\n",
      "  [-0.08 ]\n",
      "  [-0.069]\n",
      "  [-0.062]]\n",
      "\n",
      " [[ 0.076]\n",
      "  [ 0.101]\n",
      "  [ 0.127]\n",
      "  ...\n",
      "  [-0.364]\n",
      "  [-0.364]\n",
      "  [-0.363]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.017]\n",
      "  [ 0.007]\n",
      "  [ 0.041]\n",
      "  ...\n",
      "  [ 0.065]\n",
      "  [ 0.047]\n",
      "  [ 0.027]]\n",
      "\n",
      " [[-0.303]\n",
      "  [-0.376]\n",
      "  [-0.456]\n",
      "  ...\n",
      "  [ 0.186]\n",
      "  [ 0.19 ]\n",
      "  [ 0.192]]\n",
      "\n",
      " [[-0.202]\n",
      "  [-0.235]\n",
      "  [-0.272]\n",
      "  ...\n",
      "  [-0.032]\n",
      "  [-0.023]\n",
      "  [-0.015]]]\n",
      "trian: [    0     1     2 ... 10148 10149 10150] len 8121 test: [    5     7     8 ... 10134 10136 10137] len 2030\n",
      "[[[ 0.519]\n",
      "  [ 0.619]\n",
      "  [ 0.723]\n",
      "  ...\n",
      "  [ 0.116]\n",
      "  [ 0.017]\n",
      "  [ 0.018]]\n",
      "\n",
      " [[-0.188]\n",
      "  [-0.239]\n",
      "  [-0.274]\n",
      "  ...\n",
      "  [-0.077]\n",
      "  [-0.077]\n",
      "  [-0.078]]\n",
      "\n",
      " [[-0.079]\n",
      "  [-0.079]\n",
      "  [-0.079]\n",
      "  ...\n",
      "  [-0.093]\n",
      "  [-0.057]\n",
      "  [ 0.   ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.095]\n",
      "  [-0.095]\n",
      "  [-0.094]\n",
      "  ...\n",
      "  [-0.313]\n",
      "  [-0.173]\n",
      "  [-0.052]]\n",
      "\n",
      " [[-0.227]\n",
      "  [-0.297]\n",
      "  [-0.374]\n",
      "  ...\n",
      "  [-0.054]\n",
      "  [-0.044]\n",
      "  [-0.036]]\n",
      "\n",
      " [[-0.237]\n",
      "  [-0.286]\n",
      "  [-0.338]\n",
      "  ...\n",
      "  [-0.016]\n",
      "  [-0.017]\n",
      "  [-0.018]]]\n",
      "[[[-0.39 ]\n",
      "  [-0.462]\n",
      "  [-0.542]\n",
      "  ...\n",
      "  [ 0.016]\n",
      "  [ 0.009]\n",
      "  [ 0.001]]\n",
      "\n",
      " [[-0.281]\n",
      "  [-0.334]\n",
      "  [-0.393]\n",
      "  ...\n",
      "  [ 0.263]\n",
      "  [ 0.134]\n",
      "  [ 0.034]]\n",
      "\n",
      " [[ 0.017]\n",
      "  [ 0.019]\n",
      "  [ 0.021]\n",
      "  ...\n",
      "  [-0.116]\n",
      "  [-0.083]\n",
      "  [-0.052]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.599]\n",
      "  [ 0.738]\n",
      "  [ 0.894]\n",
      "  ...\n",
      "  [-0.055]\n",
      "  [-0.051]\n",
      "  [-0.049]]\n",
      "\n",
      " [[-0.026]\n",
      "  [-0.025]\n",
      "  [-0.023]\n",
      "  ...\n",
      "  [-0.029]\n",
      "  [-0.022]\n",
      "  [-0.014]]\n",
      "\n",
      " [[-0.001]\n",
      "  [-0.002]\n",
      "  [-0.003]\n",
      "  ...\n",
      "  [ 0.002]\n",
      "  [ 0.   ]\n",
      "  [-0.001]]]\n",
      "trian: [    0     1     3 ... 10147 10148 10149] len 8121 test: [    2     6    13 ... 10143 10144 10150] len 2030\n",
      "[[[ 0.519]\n",
      "  [ 0.619]\n",
      "  [ 0.723]\n",
      "  ...\n",
      "  [ 0.116]\n",
      "  [ 0.017]\n",
      "  [ 0.018]]\n",
      "\n",
      " [[-0.188]\n",
      "  [-0.239]\n",
      "  [-0.274]\n",
      "  ...\n",
      "  [-0.077]\n",
      "  [-0.077]\n",
      "  [-0.078]]\n",
      "\n",
      " [[ 0.051]\n",
      "  [ 0.056]\n",
      "  [ 0.059]\n",
      "  ...\n",
      "  [-0.08 ]\n",
      "  [-0.069]\n",
      "  [-0.062]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.202]\n",
      "  [-0.235]\n",
      "  [-0.272]\n",
      "  ...\n",
      "  [-0.032]\n",
      "  [-0.023]\n",
      "  [-0.015]]\n",
      "\n",
      " [[-0.095]\n",
      "  [-0.095]\n",
      "  [-0.094]\n",
      "  ...\n",
      "  [-0.313]\n",
      "  [-0.173]\n",
      "  [-0.052]]\n",
      "\n",
      " [[-0.227]\n",
      "  [-0.297]\n",
      "  [-0.374]\n",
      "  ...\n",
      "  [-0.054]\n",
      "  [-0.044]\n",
      "  [-0.036]]]\n",
      "[[[-0.079]\n",
      "  [-0.079]\n",
      "  [-0.079]\n",
      "  ...\n",
      "  [-0.093]\n",
      "  [-0.057]\n",
      "  [ 0.   ]]\n",
      "\n",
      " [[-1.697]\n",
      "  [-2.084]\n",
      "  [-2.491]\n",
      "  ...\n",
      "  [-0.034]\n",
      "  [-0.027]\n",
      "  [-0.022]]\n",
      "\n",
      " [[ 0.314]\n",
      "  [ 0.393]\n",
      "  [ 0.503]\n",
      "  ...\n",
      "  [-0.151]\n",
      "  [-0.113]\n",
      "  [-0.074]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.576]\n",
      "  [ 0.694]\n",
      "  [ 0.816]\n",
      "  ...\n",
      "  [ 0.075]\n",
      "  [ 0.049]\n",
      "  [-0.006]]\n",
      "\n",
      " [[-1.957]\n",
      "  [-2.338]\n",
      "  [-2.718]\n",
      "  ...\n",
      "  [ 0.689]\n",
      "  [ 0.595]\n",
      "  [ 0.394]]\n",
      "\n",
      " [[-0.237]\n",
      "  [-0.286]\n",
      "  [-0.338]\n",
      "  ...\n",
      "  [-0.016]\n",
      "  [-0.017]\n",
      "  [-0.018]]]\n",
      "trian: [    1     2     3 ... 10147 10148 10150] len 8121 test: [    0    10    16 ... 10139 10145 10149] len 2030\n",
      "[[[-0.188]\n",
      "  [-0.239]\n",
      "  [-0.274]\n",
      "  ...\n",
      "  [-0.077]\n",
      "  [-0.077]\n",
      "  [-0.078]]\n",
      "\n",
      " [[-0.079]\n",
      "  [-0.079]\n",
      "  [-0.079]\n",
      "  ...\n",
      "  [-0.093]\n",
      "  [-0.057]\n",
      "  [ 0.   ]]\n",
      "\n",
      " [[ 0.051]\n",
      "  [ 0.056]\n",
      "  [ 0.059]\n",
      "  ...\n",
      "  [-0.08 ]\n",
      "  [-0.069]\n",
      "  [-0.062]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.202]\n",
      "  [-0.235]\n",
      "  [-0.272]\n",
      "  ...\n",
      "  [-0.032]\n",
      "  [-0.023]\n",
      "  [-0.015]]\n",
      "\n",
      " [[-0.095]\n",
      "  [-0.095]\n",
      "  [-0.094]\n",
      "  ...\n",
      "  [-0.313]\n",
      "  [-0.173]\n",
      "  [-0.052]]\n",
      "\n",
      " [[-0.237]\n",
      "  [-0.286]\n",
      "  [-0.338]\n",
      "  ...\n",
      "  [-0.016]\n",
      "  [-0.017]\n",
      "  [-0.018]]]\n",
      "[[[ 0.519]\n",
      "  [ 0.619]\n",
      "  [ 0.723]\n",
      "  ...\n",
      "  [ 0.116]\n",
      "  [ 0.017]\n",
      "  [ 0.018]]\n",
      "\n",
      " [[-0.093]\n",
      "  [-0.13 ]\n",
      "  [-0.173]\n",
      "  ...\n",
      "  [-0.041]\n",
      "  [-0.042]\n",
      "  [-0.041]]\n",
      "\n",
      " [[-0.885]\n",
      "  [-1.059]\n",
      "  [-1.229]\n",
      "  ...\n",
      "  [-0.028]\n",
      "  [-0.015]\n",
      "  [-0.004]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.421]\n",
      "  [ 0.502]\n",
      "  [ 0.588]\n",
      "  ...\n",
      "  [-0.037]\n",
      "  [-0.033]\n",
      "  [-0.026]]\n",
      "\n",
      " [[-0.005]\n",
      "  [-0.006]\n",
      "  [-0.008]\n",
      "  ...\n",
      "  [ 0.024]\n",
      "  [ 0.026]\n",
      "  [ 0.026]]\n",
      "\n",
      " [[-0.227]\n",
      "  [-0.297]\n",
      "  [-0.374]\n",
      "  ...\n",
      "  [-0.054]\n",
      "  [-0.044]\n",
      "  [-0.036]]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "print(kf)\n",
    "\n",
    "for train_index, test_index in kf.split(trainData):\n",
    "    print('trian:', train_index, 'len', len(train_index), 'test:', test_index, 'len', len(test_index))\n",
    "    print(trainData[train_index])\n",
    "    print(trainData[test_index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T10:18:35.141582Z",
     "start_time": "2018-09-05T10:17:56.298684Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "Epoch 1/80\n",
      "8120/8120 [==============================] - 9s 1ms/step - loss: 1.0606 - acc: 0.5765\n",
      "Epoch 2/80\n",
      "8120/8120 [==============================] - 9s 1ms/step - loss: 0.9917 - acc: 0.5846\n",
      "Epoch 3/80\n",
      "8120/8120 [==============================] - 9s 1ms/step - loss: 0.9371 - acc: 0.5899\n",
      "Epoch 4/80\n",
      "8120/8120 [==============================] - 8s 1ms/step - loss: 0.8927 - acc: 0.6148\n",
      "Epoch 5/80\n",
      "1650/8120 [=====>........................] - ETA: 6s - loss: 0.8555 - acc: 0.6491"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-21a19678f899>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKerasClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuild_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameter_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainLabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m '''\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Invalid shape for y: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    963\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1667\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1669\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1204\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1206\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1207\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "def create_model(learning_rate=0):\n",
    "    model = Sequential() \n",
    "    model.add(Conv1D(filters = 32, kernel_size = 7, input_shape = (trainData.shape[1], 1)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size = 2))\n",
    "\n",
    "    model.add(Conv1D(filters = 32, kernel_size = 7))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling1D(pool_size = 2))\n",
    "\n",
    "    model.add(Conv1D(filters = 64, kernel_size = 7))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling1D(pool_size = 2))\n",
    "\n",
    "    model.add(Conv1D(filters = 64, kernel_size = 3))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling1D(pool_size = 2))\n",
    "\n",
    "    model.add(Conv1D(filters = 128, kernel_size = 3))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling1D(pool_size = 2))\n",
    "\n",
    "    model.add(Conv1D(filters = 128, kernel_size = 3))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling1D(pool_size = 2))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Conv1D(filters = 256, kernel_size = 3))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling1D(pool_size = 2))\n",
    "\n",
    "    model.add(Conv1D(filters = 256, kernel_size = 3))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling1D(pool_size = 2))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Conv1D(filters = 512, kernel_size = 3))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling1D(pool_size = 2))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Conv1D(filters = 512, kernel_size = 3))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation = 'relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(32, activation = 'relu'))\n",
    "    model.add(Dense(4, activation = \"softmax\"))\n",
    "    \n",
    "    adam = Adam(lr = learning_rate)\n",
    "    model.compile(optimizer = adam, loss = \"categorical_crossentropy\", metrics=['accuracy'])\n",
    "#     print('Model finished!')\n",
    "    \n",
    "    return model\n",
    "\n",
    "F1_result = []\n",
    "\n",
    "batch_S = [30, 50, 70, 90, 120]\n",
    "learning_rate = [0.00005, 0.0001, 0.0005, 0.001, 0.005]\n",
    "parameter_grid = dict(batch_size=batch_S, learning_rate=learning_rate)\n",
    "# early_stop = EarlyStopping(patience=20)\n",
    "model = KerasClassifier(build_fn = create_model, epochs=80, verbose=1)\n",
    "grid = GridSearchCV(estimator=model, param_grid=parameter_grid, cv=kf, verbose = 1)\n",
    "grid_result = grid.fit(trainData, trainLabel)\n",
    "\n",
    "'''\n",
    "for X_train, Y_train, X_val, Y_val, val_cat in zip(training_data, training_label, validation_data, validation_label, validation_cate_label):\n",
    "        \n",
    "    model = model_structure()\n",
    "    \n",
    "    early_stop = EarlyStopping(patience=20)\n",
    "    train_history_1 = model.fit(x = X_train, \n",
    "                                y = Y_train,\n",
    "                                epochs=80,\n",
    "                                validation_data=(X_val, Y_val),\n",
    "                                callbacks=[early_stop],\n",
    "                                batch_size=100, \n",
    "                                verbose=1)\n",
    "    evaluation = model.evaluate(x = X_val, y = Y_val)\n",
    "    print('Loss: {:.3f}, Accuracy: {:.3f}'.format(evaluation[0], evaluation[1]))\n",
    "    \n",
    "    validation_prediction = model.predict_classes(X_val, batch_size=100)\n",
    "    result = f1_score(val_cat, validation_prediction, average=None)\n",
    "    F1_result.append(result)\n",
    "    del model\n",
    "'''\n",
    "\n",
    "print('Finish training!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-31T06:18:40.724569Z",
     "start_time": "2018-08-31T06:18:40.715289Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7102748500716274"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-31T06:18:44.472807Z",
     "start_time": "2018-08-31T06:18:44.464927Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 60}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-31T06:47:46.188781Z",
     "start_time": "2018-08-31T06:47:46.179484Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.710275 (0.012190) with: {'batch_size': 60}\n",
      "0.698355 (0.022026) with: {'batch_size': 80}\n",
      "0.689095 (0.023570) with: {'batch_size': 100}\n"
     ]
    }
   ],
   "source": [
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"Mean:%f (STD:%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-06T06:29:54.306041Z",
     "start_time": "2018-08-06T06:29:54.298805Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.80653951, 0.72413793, 0.91091493, 0.7525299 ]), array([0.71134021, 0.69230769, 0.89750919, 0.71546203]), array([0.69295775, 0.62068966, 0.89452496, 0.68959108]), array([0.78181818, 0.51724138, 0.90533981, 0.7530648 ]), array([0.80108992, 0.52427184, 0.91609242, 0.76758682])]\n"
     ]
    }
   ],
   "source": [
    "print(F1_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-06T06:30:09.436069Z",
     "start_time": "2018-08-06T06:30:09.423400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<avg>\n",
      "AF: 0.7587491124551075\n",
      "Noise: 0.6157297004970255\n",
      "Normal: 0.9048762601406286\n",
      "Other: 0.7356469255184189\n"
     ]
    }
   ],
   "source": [
    "tmp = [0,0,0,0]\n",
    "for i in F1_result:\n",
    "    tmp += i\n",
    "\n",
    "tmp /= 5\n",
    "print(\"<avg>\")\n",
    "print(\"AF: {}\".format(tmp[0]))\n",
    "print(\"Noise: {}\".format(tmp[1]))\n",
    "print(\"Normal: {}\".format(tmp[2]))\n",
    "print(\"Other: {}\".format(tmp[3]))\n",
    "\n",
    "# AF Noise Normal Other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Check Tensorflow & Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.0'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.1.3'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
