{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 70:30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/hsiehch/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/hsiehch/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/hsiehch/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/hsiehch/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/hsiehch/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/hsiehch/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: 903\n",
      "~: 299\n",
      "O: 2990\n",
      "N: 5959\n",
      "split train data index:  [[0, 633, 904, 903], [903, 1113, 1203, 1202], [1202, 3296, 4194, 4192], [4192, 8364, 10152, 10151]]\n",
      "(7109, 9000)\n",
      "(7109,)\n",
      "(3042, 9000)\n",
      "(3042,)\n",
      "(0,)\n",
      "(0,)\n",
      "Train Data: (7109, 9000, 1)\n",
      "Train Label:  (7109, 4)\n",
      "Train Data: (3042, 9000, 1)\n",
      "Train Label:  (3042, 4)\n",
      "Index 1\n",
      "3042/3042 [==============================] - 1s 393us/step\n",
      "[0.76190476 0.60377358 0.89789303 0.70417193]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import itertools\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import f1_score\n",
    "import tools_split_70_30 as tools\n",
    "\n",
    "training_data, training_label, validation_data, validation_label, validation_cate_label = tools.get_data()\n",
    "\n",
    "kernel_size = [5]\n",
    "num_layers = [10]\n",
    "batch_size = [30]\n",
    "learning_rate = [0.0001]\n",
    "overflow_model = 0\n",
    "\n",
    "def run(bs, lr, ks, num_layer):\n",
    "    model = tools.create_model(lr, bs, ks, num_layer)\n",
    "    early_stop = EarlyStopping(patience=20)\n",
    "    history = model.fit(x = training_data, \n",
    "                        y = training_label,\n",
    "                        epochs=80,\n",
    "                        validation_data=(validation_data, validation_label),\n",
    "                        callbacks=[early_stop],\n",
    "                        batch_size=bs, \n",
    "                        verbose=1)\n",
    "    evaluation = model.evaluate(x = validation_data, y = validation_label)\n",
    "    validation_prediction = model.predict_classes(validation_data, batch_size=bs)\n",
    "    score = f1_score(validation_cate_label, validation_prediction, average=None)\n",
    "    \n",
    "    del model\n",
    "    return score\n",
    "\n",
    "## main()\n",
    "\n",
    "index=1\n",
    "for ks, num_layer, bs, lr in itertools.product(kernel_size, num_layers, batch_size, learning_rate):\n",
    "    print(\"Index \"+str(index))\n",
    "    \n",
    "    model = tools.create_model(lr, bs, ks, num_layer)\n",
    "    \n",
    "    score = run(bs, lr, ks, num_layer)\n",
    "    print(score)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 80:20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/hsiehch/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/hsiehch/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/hsiehch/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/hsiehch/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/hsiehch/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/hsiehch/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: 903\n",
      "~: 299\n",
      "O: 2990\n",
      "N: 5959\n",
      "split train data index:  [[0, 723, 904, 903], [903, 1143, 1203, 1202], [1202, 3595, 4194, 4192], [4192, 8960, 10152, 10151]]\n",
      "(8124, 9000)\n",
      "(8124,)\n",
      "(2027, 9000)\n",
      "(2027,)\n",
      "(0,)\n",
      "(0,)\n",
      "Train Data: (8124, 9000, 1)\n",
      "Train Label:  (8124, 4)\n",
      "Train Data: (2027, 9000, 1)\n",
      "Train Label:  (2027, 4)\n",
      "Index 1\n",
      "Train on 8124 samples, validate on 2027 samples\n",
      "Epoch 1/80\n",
      "8124/8124 [==============================] - 12s 1ms/step - loss: 1.0672 - acc: 0.5469 - val_loss: 0.9889 - val_acc: 0.5876\n",
      "Epoch 2/80\n",
      "8124/8124 [==============================] - 9s 1ms/step - loss: 0.9282 - acc: 0.5940 - val_loss: 0.8837 - val_acc: 0.6300\n",
      "Epoch 3/80\n",
      "8124/8124 [==============================] - 9s 1ms/step - loss: 0.8500 - acc: 0.6343 - val_loss: 0.8053 - val_acc: 0.6566\n",
      "Epoch 4/80\n",
      "8124/8124 [==============================] - 9s 1ms/step - loss: 0.8067 - acc: 0.6574 - val_loss: 0.7597 - val_acc: 0.6877\n",
      "Epoch 5/80\n",
      "8124/8124 [==============================] - 9s 1ms/step - loss: 0.7598 - acc: 0.6838 - val_loss: 0.7344 - val_acc: 0.6749\n",
      "Epoch 6/80\n",
      "8124/8124 [==============================] - 9s 1ms/step - loss: 0.7194 - acc: 0.6992 - val_loss: 0.6856 - val_acc: 0.7010\n",
      "Epoch 7/80\n",
      "8124/8124 [==============================] - 9s 1ms/step - loss: 0.6715 - acc: 0.7232 - val_loss: 0.6908 - val_acc: 0.7074\n",
      "Epoch 8/80\n",
      "8124/8124 [==============================] - 9s 1ms/step - loss: 0.6392 - acc: 0.7388 - val_loss: 0.6273 - val_acc: 0.7193\n",
      "Epoch 9/80\n",
      "8124/8124 [==============================] - 9s 1ms/step - loss: 0.5975 - acc: 0.7569 - val_loss: 0.5841 - val_acc: 0.7617\n",
      "Epoch 10/80\n",
      "8124/8124 [==============================] - 9s 1ms/step - loss: 0.5591 - acc: 0.7762 - val_loss: 0.5352 - val_acc: 0.7839\n",
      "Epoch 11/80\n",
      "8124/8124 [==============================] - 9s 1ms/step - loss: 0.5362 - acc: 0.7928 - val_loss: 0.5115 - val_acc: 0.7982\n",
      "Epoch 12/80\n",
      "8124/8124 [==============================] - 9s 1ms/step - loss: 0.5100 - acc: 0.8027 - val_loss: 0.5017 - val_acc: 0.8106\n",
      "Epoch 13/80\n",
      "8124/8124 [==============================] - 9s 1ms/step - loss: 0.4986 - acc: 0.8147 - val_loss: 0.5027 - val_acc: 0.8106\n",
      "Epoch 14/80\n",
      "8124/8124 [==============================] - 9s 1ms/step - loss: 0.4765 - acc: 0.8189 - val_loss: 0.4761 - val_acc: 0.8209\n",
      "Epoch 15/80\n",
      "8124/8124 [==============================] - 9s 1ms/step - loss: 0.4664 - acc: 0.8253 - val_loss: 0.4671 - val_acc: 0.8229\n",
      "Epoch 16/80\n",
      "8124/8124 [==============================] - 9s 1ms/step - loss: 0.4426 - acc: 0.8368 - val_loss: 0.4834 - val_acc: 0.8115\n",
      "Epoch 17/80\n",
      "8124/8124 [==============================] - 9s 1ms/step - loss: 0.4486 - acc: 0.8335 - val_loss: 0.4747 - val_acc: 0.8175\n",
      "Epoch 18/80\n",
      "8124/8124 [==============================] - 9s 1ms/step - loss: 0.4252 - acc: 0.8419 - val_loss: 0.4644 - val_acc: 0.8189\n",
      "Epoch 19/80\n",
      "8124/8124 [==============================] - 9s 1ms/step - loss: 0.4201 - acc: 0.8490 - val_loss: 0.4787 - val_acc: 0.8115\n",
      "Epoch 20/80\n",
      "8124/8124 [==============================] - 9s 1ms/step - loss: 0.4107 - acc: 0.8518 - val_loss: 0.4613 - val_acc: 0.8229\n",
      "Epoch 21/80\n",
      "8124/8124 [==============================] - 9s 1ms/step - loss: 0.4051 - acc: 0.8536 - val_loss: 0.4387 - val_acc: 0.8293\n",
      "Epoch 22/80\n",
      "8124/8124 [==============================] - 9s 1ms/step - loss: 0.3981 - acc: 0.8573 - val_loss: 0.4641 - val_acc: 0.8180\n",
      "Epoch 23/80\n",
      "8124/8124 [==============================] - 9s 1ms/step - loss: 0.3788 - acc: 0.8614 - val_loss: 0.4450 - val_acc: 0.8214\n",
      "Epoch 24/80\n",
      "8124/8124 [==============================] - 9s 1ms/step - loss: 0.3771 - acc: 0.8634 - val_loss: 0.4327 - val_acc: 0.8323\n",
      "Epoch 25/80\n",
      "8124/8124 [==============================] - 9s 1ms/step - loss: 0.3733 - acc: 0.8656 - val_loss: 0.4607 - val_acc: 0.8229\n",
      "Epoch 26/80\n",
      "8124/8124 [==============================] - 9s 1ms/step - loss: 0.3561 - acc: 0.8740 - val_loss: 0.4714 - val_acc: 0.8189\n",
      "Epoch 27/80\n",
      "8124/8124 [==============================] - 9s 1ms/step - loss: 0.3599 - acc: 0.8696 - val_loss: 0.4419 - val_acc: 0.8337\n",
      "Epoch 28/80\n",
      "8124/8124 [==============================] - 9s 1ms/step - loss: 0.3405 - acc: 0.8808 - val_loss: 0.4639 - val_acc: 0.8263\n",
      "Epoch 29/80\n",
      "8124/8124 [==============================] - 9s 1ms/step - loss: 0.3359 - acc: 0.8780 - val_loss: 0.4610 - val_acc: 0.8323\n",
      "Epoch 30/80\n",
      "8124/8124 [==============================] - 9s 1ms/step - loss: 0.3341 - acc: 0.8824 - val_loss: 0.4693 - val_acc: 0.8303\n",
      "Epoch 31/80\n",
      "8124/8124 [==============================] - 9s 1ms/step - loss: 0.3276 - acc: 0.8839 - val_loss: 0.4615 - val_acc: 0.8303\n",
      "Epoch 32/80\n",
      "8124/8124 [==============================] - 9s 1ms/step - loss: 0.3207 - acc: 0.8837 - val_loss: 0.4544 - val_acc: 0.8347\n",
      "Epoch 33/80\n",
      "8124/8124 [==============================] - 9s 1ms/step - loss: 0.3196 - acc: 0.8877 - val_loss: 0.4572 - val_acc: 0.8323\n",
      "Epoch 34/80\n",
      "8124/8124 [==============================] - 9s 1ms/step - loss: 0.3038 - acc: 0.8948 - val_loss: 0.4524 - val_acc: 0.8273\n",
      "Epoch 35/80\n",
      "8124/8124 [==============================] - 9s 1ms/step - loss: 0.2951 - acc: 0.8933 - val_loss: 0.4859 - val_acc: 0.8239\n",
      "Epoch 36/80\n",
      "8124/8124 [==============================] - 9s 1ms/step - loss: 0.2918 - acc: 0.8981 - val_loss: 0.4833 - val_acc: 0.8130\n",
      "Epoch 37/80\n",
      "8124/8124 [==============================] - 9s 1ms/step - loss: 0.2803 - acc: 0.9003 - val_loss: 0.4523 - val_acc: 0.8337\n",
      "Epoch 38/80\n",
      "8124/8124 [==============================] - 9s 1ms/step - loss: 0.2873 - acc: 0.9050 - val_loss: 0.4867 - val_acc: 0.8263\n",
      "Epoch 39/80\n",
      "8124/8124 [==============================] - 9s 1ms/step - loss: 0.2760 - acc: 0.9005 - val_loss: 0.4610 - val_acc: 0.8273\n",
      "Epoch 40/80\n",
      "8124/8124 [==============================] - 9s 1ms/step - loss: 0.2652 - acc: 0.9089 - val_loss: 0.5437 - val_acc: 0.8046\n",
      "Epoch 41/80\n",
      "8124/8124 [==============================] - 9s 1ms/step - loss: 0.2717 - acc: 0.9042 - val_loss: 0.5103 - val_acc: 0.8189\n",
      "Epoch 42/80\n",
      "8124/8124 [==============================] - 9s 1ms/step - loss: 0.2605 - acc: 0.9087 - val_loss: 0.5174 - val_acc: 0.8273\n",
      "Epoch 43/80\n",
      "8124/8124 [==============================] - 9s 1ms/step - loss: 0.2524 - acc: 0.9125 - val_loss: 0.5115 - val_acc: 0.8135\n",
      "Epoch 44/80\n",
      "8124/8124 [==============================] - 9s 1ms/step - loss: 0.2558 - acc: 0.9149 - val_loss: 0.4945 - val_acc: 0.8283\n",
      "2027/2027 [==============================] - 1s 429us/step\n",
      "[0.76884422 0.66666667 0.89426752 0.73519164]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import itertools\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import f1_score\n",
    "import tools_split_80_20 as tools\n",
    "\n",
    "training_data, training_label, validation_data, validation_label, validation_cate_label = tools.get_data()\n",
    "\n",
    "kernel_size = [5]\n",
    "num_layers = [10]\n",
    "batch_size = [30]\n",
    "learning_rate = [0.0001]\n",
    "overflow_model = 0\n",
    "\n",
    "def run(bs, lr, ks, num_layer):\n",
    "    model = tools.create_model(lr, bs, ks, num_layer)\n",
    "    early_stop = EarlyStopping(patience=20)\n",
    "    history = model.fit(x = training_data, \n",
    "                        y = training_label,\n",
    "                        epochs=80,\n",
    "                        validation_data=(validation_data, validation_label),\n",
    "                        callbacks=[early_stop],\n",
    "                        batch_size=bs, \n",
    "                        verbose=1)\n",
    "    evaluation = model.evaluate(x = validation_data, y = validation_label)\n",
    "    validation_prediction = model.predict_classes(validation_data, batch_size=bs)\n",
    "    score = f1_score(validation_cate_label, validation_prediction, average=None)\n",
    "    \n",
    "    del model\n",
    "    return score\n",
    "\n",
    "## main()\n",
    "\n",
    "index=1\n",
    "for ks, num_layer, bs, lr in itertools.product(kernel_size, num_layers, batch_size, learning_rate):\n",
    "    print(\"Index \"+str(index))\n",
    "    \n",
    "    model = tools.create_model(lr, bs, ks, num_layer)\n",
    "    \n",
    "    score = run(bs, lr, ks, num_layer)\n",
    "    print(score)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 60:40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/hsiehch/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/hsiehch/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/hsiehch/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/hsiehch/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/hsiehch/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/hsiehch/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: 903\n",
      "~: 299\n",
      "O: 2990\n",
      "N: 5959\n",
      "split train data index:  [[0, 542, 904, 903], [903, 1083, 1203, 1202], [1202, 2997, 4194, 4192], [4192, 7768, 10152, 10151]]\n",
      "(6093, 9000)\n",
      "(6093,)\n",
      "(4058, 9000)\n",
      "(4058,)\n",
      "(0,)\n",
      "(0,)\n",
      "Train Data: (6093, 9000, 1)\n",
      "Train Label:  (6093, 4)\n",
      "Train Data: (4058, 9000, 1)\n",
      "Train Label:  (4058, 4)\n",
      "Index 1\n",
      "Train on 6093 samples, validate on 4058 samples\n",
      "Epoch 1/80\n",
      "6093/6093 [==============================] - 18s 3ms/step - loss: 1.0304 - acc: 0.5744 - val_loss: 0.9840 - val_acc: 0.5872\n",
      "Epoch 2/80\n",
      "6093/6093 [==============================] - 7s 1ms/step - loss: 0.9425 - acc: 0.5858 - val_loss: 0.9043 - val_acc: 0.5885\n",
      "Epoch 3/80\n",
      "6093/6093 [==============================] - 7s 1ms/step - loss: 0.8967 - acc: 0.6063 - val_loss: 0.8524 - val_acc: 0.6279\n",
      "Epoch 4/80\n",
      "6093/6093 [==============================] - 8s 1ms/step - loss: 0.8518 - acc: 0.6283 - val_loss: 0.8109 - val_acc: 0.6419\n",
      "Epoch 5/80\n",
      "6093/6093 [==============================] - 8s 1ms/step - loss: 0.8114 - acc: 0.6529 - val_loss: 0.7782 - val_acc: 0.6597\n",
      "Epoch 6/80\n",
      "6093/6093 [==============================] - 8s 1ms/step - loss: 0.7668 - acc: 0.6745 - val_loss: 0.7414 - val_acc: 0.6614\n",
      "Epoch 7/80\n",
      "6093/6093 [==============================] - 8s 1ms/step - loss: 0.7214 - acc: 0.6964 - val_loss: 0.7032 - val_acc: 0.6814\n",
      "Epoch 8/80\n",
      "6093/6093 [==============================] - 8s 1ms/step - loss: 0.6780 - acc: 0.7190 - val_loss: 0.7158 - val_acc: 0.6836\n",
      "Epoch 9/80\n",
      "6093/6093 [==============================] - 8s 1ms/step - loss: 0.6525 - acc: 0.7322 - val_loss: 0.6660 - val_acc: 0.6949\n",
      "Epoch 10/80\n",
      "6093/6093 [==============================] - 8s 1ms/step - loss: 0.6114 - acc: 0.7491 - val_loss: 0.5972 - val_acc: 0.7427\n",
      "Epoch 11/80\n",
      "6093/6093 [==============================] - 8s 1ms/step - loss: 0.5809 - acc: 0.7592 - val_loss: 0.5987 - val_acc: 0.7479\n",
      "Epoch 12/80\n",
      "6093/6093 [==============================] - 8s 1ms/step - loss: 0.5585 - acc: 0.7809 - val_loss: 0.5495 - val_acc: 0.7733\n",
      "Epoch 13/80\n",
      "6093/6093 [==============================] - 8s 1ms/step - loss: 0.5362 - acc: 0.7927 - val_loss: 0.5305 - val_acc: 0.7841\n",
      "Epoch 14/80\n",
      "6093/6093 [==============================] - 8s 1ms/step - loss: 0.5190 - acc: 0.8027 - val_loss: 0.5326 - val_acc: 0.7925\n",
      "Epoch 15/80\n",
      "6093/6093 [==============================] - 8s 1ms/step - loss: 0.4921 - acc: 0.8172 - val_loss: 0.5307 - val_acc: 0.7982\n",
      "Epoch 16/80\n",
      "6093/6093 [==============================] - 8s 1ms/step - loss: 0.4831 - acc: 0.8213 - val_loss: 0.4999 - val_acc: 0.8041\n",
      "Epoch 17/80\n",
      "6093/6093 [==============================] - 8s 1ms/step - loss: 0.4661 - acc: 0.8293 - val_loss: 0.5752 - val_acc: 0.7918\n",
      "Epoch 18/80\n",
      "6093/6093 [==============================] - 8s 1ms/step - loss: 0.4607 - acc: 0.8311 - val_loss: 0.4879 - val_acc: 0.8117\n",
      "Epoch 19/80\n",
      "6093/6093 [==============================] - 8s 1ms/step - loss: 0.4537 - acc: 0.8300 - val_loss: 0.4984 - val_acc: 0.7994\n",
      "Epoch 20/80\n",
      "6093/6093 [==============================] - 8s 1ms/step - loss: 0.4243 - acc: 0.8523 - val_loss: 0.4812 - val_acc: 0.8184\n",
      "Epoch 21/80\n",
      "6093/6093 [==============================] - 8s 1ms/step - loss: 0.4337 - acc: 0.8433 - val_loss: 0.4977 - val_acc: 0.8056\n",
      "Epoch 22/80\n",
      "6093/6093 [==============================] - 8s 1ms/step - loss: 0.4122 - acc: 0.8529 - val_loss: 0.4849 - val_acc: 0.8172\n",
      "Epoch 23/80\n",
      "6093/6093 [==============================] - 8s 1ms/step - loss: 0.4122 - acc: 0.8552 - val_loss: 0.4884 - val_acc: 0.8189\n",
      "Epoch 24/80\n",
      "6093/6093 [==============================] - 8s 1ms/step - loss: 0.3961 - acc: 0.8587 - val_loss: 0.5177 - val_acc: 0.8144\n",
      "Epoch 25/80\n",
      "6093/6093 [==============================] - 8s 1ms/step - loss: 0.3930 - acc: 0.8566 - val_loss: 0.4847 - val_acc: 0.8223\n",
      "Epoch 26/80\n",
      "6093/6093 [==============================] - 8s 1ms/step - loss: 0.3825 - acc: 0.8582 - val_loss: 0.4814 - val_acc: 0.8169\n",
      "Epoch 27/80\n",
      "6093/6093 [==============================] - 8s 1ms/step - loss: 0.3697 - acc: 0.8697 - val_loss: 0.4951 - val_acc: 0.8169\n",
      "Epoch 28/80\n",
      "6093/6093 [==============================] - 8s 1ms/step - loss: 0.3844 - acc: 0.8643 - val_loss: 0.5194 - val_acc: 0.8169\n",
      "Epoch 29/80\n",
      "6093/6093 [==============================] - 8s 1ms/step - loss: 0.3617 - acc: 0.8689 - val_loss: 0.5163 - val_acc: 0.8157\n",
      "Epoch 30/80\n",
      "6093/6093 [==============================] - 8s 1ms/step - loss: 0.3506 - acc: 0.8707 - val_loss: 0.5277 - val_acc: 0.8184\n",
      "Epoch 31/80\n",
      "6093/6093 [==============================] - 8s 1ms/step - loss: 0.3440 - acc: 0.8799 - val_loss: 0.4824 - val_acc: 0.8228\n",
      "Epoch 32/80\n",
      "6093/6093 [==============================] - 8s 1ms/step - loss: 0.3214 - acc: 0.8882 - val_loss: 0.5178 - val_acc: 0.8120\n",
      "Epoch 33/80\n",
      "6093/6093 [==============================] - 8s 1ms/step - loss: 0.3311 - acc: 0.8858 - val_loss: 0.5280 - val_acc: 0.8122\n",
      "Epoch 34/80\n",
      "6093/6093 [==============================] - 8s 1ms/step - loss: 0.3218 - acc: 0.8927 - val_loss: 0.5245 - val_acc: 0.8154\n",
      "Epoch 35/80\n",
      "6093/6093 [==============================] - 8s 1ms/step - loss: 0.3149 - acc: 0.8925 - val_loss: 0.5173 - val_acc: 0.8231\n",
      "Epoch 36/80\n",
      "6093/6093 [==============================] - 8s 1ms/step - loss: 0.2966 - acc: 0.8981 - val_loss: 0.5677 - val_acc: 0.8248\n",
      "Epoch 37/80\n",
      "6093/6093 [==============================] - 8s 1ms/step - loss: 0.3069 - acc: 0.8912 - val_loss: 0.4997 - val_acc: 0.8122\n",
      "Epoch 38/80\n",
      "6093/6093 [==============================] - 8s 1ms/step - loss: 0.2866 - acc: 0.9012 - val_loss: 0.5278 - val_acc: 0.8260\n",
      "Epoch 39/80\n",
      "6093/6093 [==============================] - 8s 1ms/step - loss: 0.2854 - acc: 0.8994 - val_loss: 0.5006 - val_acc: 0.8216\n",
      "Epoch 40/80\n",
      "6093/6093 [==============================] - 8s 1ms/step - loss: 0.2715 - acc: 0.9065 - val_loss: 0.5550 - val_acc: 0.8184\n",
      "4058/4058 [==============================] - 1s 355us/step\n",
      "[0.72244356 0.60273973 0.896538   0.68932956]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import itertools\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import f1_score\n",
    "import tools_split_60_40 as tools\n",
    "\n",
    "training_data, training_label, validation_data, validation_label, validation_cate_label = tools.get_data()\n",
    "\n",
    "kernel_size = [5]\n",
    "num_layers = [10]\n",
    "batch_size = [30]\n",
    "learning_rate = [0.0001]\n",
    "overflow_model = 0\n",
    "\n",
    "def run(bs, lr, ks, num_layer):\n",
    "    model = tools.create_model(lr, bs, ks, num_layer)\n",
    "    early_stop = EarlyStopping(patience=20)\n",
    "    history = model.fit(x = training_data, \n",
    "                        y = training_label,\n",
    "                        epochs=80,\n",
    "                        validation_data=(validation_data, validation_label),\n",
    "                        callbacks=[early_stop],\n",
    "                        batch_size=bs, \n",
    "                        verbose=1)\n",
    "    evaluation = model.evaluate(x = validation_data, y = validation_label)\n",
    "    validation_prediction = model.predict_classes(validation_data, batch_size=bs)\n",
    "    score = f1_score(validation_cate_label, validation_prediction, average=None)\n",
    "    \n",
    "    del model\n",
    "    return score\n",
    "\n",
    "## main()\n",
    "\n",
    "index=1\n",
    "for ks, num_layer, bs, lr in itertools.product(kernel_size, num_layers, batch_size, learning_rate):\n",
    "    print(\"Index \"+str(index))\n",
    "    \n",
    "    model = tools.create_model(lr, bs, ks, num_layer)\n",
    "    \n",
    "    score = run(bs, lr, ks, num_layer)\n",
    "    print(score)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 90:10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: 903\n",
      "~: 299\n",
      "O: 2990\n",
      "N: 5959\n",
      "split train data index:  [[0, 813, 904, 903], [903, 1173, 1203, 1202], [1202, 3894, 4194, 4192], [4192, 9556, 10152, 10151]]\n",
      "(9139, 9000)\n",
      "(9139,)\n",
      "(1012, 9000)\n",
      "(1012,)\n",
      "(0,)\n",
      "(0,)\n",
      "Train Data: (9139, 9000, 1)\n",
      "Train Label:  (9139, 4)\n",
      "Train Data: (1012, 9000, 1)\n",
      "Train Label:  (1012, 4)\n",
      "Index 1\n",
      "Train on 9139 samples, validate on 1012 samples\n",
      "Epoch 1/80\n",
      "9139/9139 [==============================] - 13s 1ms/step - loss: 1.0237 - acc: 0.5722 - val_loss: 1.0493 - val_acc: 0.5879\n",
      "Epoch 2/80\n",
      "9139/9139 [==============================] - 9s 992us/step - loss: 0.9294 - acc: 0.5920 - val_loss: 0.9925 - val_acc: 0.6285\n",
      "Epoch 3/80\n",
      "9139/9139 [==============================] - 9s 977us/step - loss: 0.8712 - acc: 0.6323 - val_loss: 0.7900 - val_acc: 0.6561\n",
      "Epoch 4/80\n",
      "9139/9139 [==============================] - 9s 991us/step - loss: 0.8067 - acc: 0.6604 - val_loss: 0.7664 - val_acc: 0.6482\n",
      "Epoch 5/80\n",
      "9139/9139 [==============================] - 9s 991us/step - loss: 0.7313 - acc: 0.6926 - val_loss: 0.6721 - val_acc: 0.6828\n",
      "Epoch 6/80\n",
      "9139/9139 [==============================] - 9s 984us/step - loss: 0.6725 - acc: 0.7280 - val_loss: 0.6413 - val_acc: 0.7391\n",
      "Epoch 7/80\n",
      "9139/9139 [==============================] - 9s 964us/step - loss: 0.6150 - acc: 0.7470 - val_loss: 0.5707 - val_acc: 0.7668\n",
      "Epoch 8/80\n",
      "9139/9139 [==============================] - 9s 970us/step - loss: 0.5742 - acc: 0.7677 - val_loss: 0.5565 - val_acc: 0.7777\n",
      "Epoch 9/80\n",
      "9139/9139 [==============================] - 9s 956us/step - loss: 0.5467 - acc: 0.7917 - val_loss: 0.5327 - val_acc: 0.7984\n",
      "Epoch 10/80\n",
      "9139/9139 [==============================] - 9s 1ms/step - loss: 0.5168 - acc: 0.8019 - val_loss: 0.5275 - val_acc: 0.7905\n",
      "Epoch 11/80\n",
      "9139/9139 [==============================] - 9s 997us/step - loss: 0.5069 - acc: 0.8059 - val_loss: 0.4922 - val_acc: 0.8063\n",
      "Epoch 12/80\n",
      "9139/9139 [==============================] - 9s 1ms/step - loss: 0.4749 - acc: 0.8198 - val_loss: 0.4919 - val_acc: 0.8162\n",
      "Epoch 13/80\n",
      "9139/9139 [==============================] - 9s 1000us/step - loss: 0.4732 - acc: 0.8255 - val_loss: 0.4977 - val_acc: 0.8182\n",
      "Epoch 14/80\n",
      "9139/9139 [==============================] - 9s 1ms/step - loss: 0.4526 - acc: 0.8332 - val_loss: 0.4983 - val_acc: 0.8142\n",
      "Epoch 15/80\n",
      "9139/9139 [==============================] - 9s 1ms/step - loss: 0.4348 - acc: 0.8388 - val_loss: 0.4680 - val_acc: 0.8192\n",
      "Epoch 16/80\n",
      "9139/9139 [==============================] - 9s 1ms/step - loss: 0.4261 - acc: 0.8455 - val_loss: 0.4709 - val_acc: 0.8231\n",
      "Epoch 17/80\n",
      "9139/9139 [==============================] - 9s 1ms/step - loss: 0.4197 - acc: 0.8452 - val_loss: 0.4643 - val_acc: 0.8192\n",
      "Epoch 18/80\n",
      "9139/9139 [==============================] - 9s 1ms/step - loss: 0.4116 - acc: 0.8509 - val_loss: 0.4814 - val_acc: 0.8024\n",
      "Epoch 19/80\n",
      "9139/9139 [==============================] - 9s 998us/step - loss: 0.4129 - acc: 0.8452 - val_loss: 0.4832 - val_acc: 0.8192\n",
      "Epoch 20/80\n",
      "9139/9139 [==============================] - 9s 993us/step - loss: 0.3927 - acc: 0.8546 - val_loss: 0.4579 - val_acc: 0.8221\n",
      "Epoch 21/80\n",
      "9139/9139 [==============================] - 9s 972us/step - loss: 0.3825 - acc: 0.8585 - val_loss: 0.4660 - val_acc: 0.8281\n",
      "Epoch 22/80\n",
      "9139/9139 [==============================] - 9s 985us/step - loss: 0.3786 - acc: 0.8641 - val_loss: 0.4767 - val_acc: 0.8281\n",
      "Epoch 23/80\n",
      "9139/9139 [==============================] - 9s 994us/step - loss: 0.3760 - acc: 0.8638 - val_loss: 0.4551 - val_acc: 0.8281\n",
      "Epoch 24/80\n",
      "9139/9139 [==============================] - 9s 979us/step - loss: 0.3663 - acc: 0.8684 - val_loss: 0.4520 - val_acc: 0.8281\n",
      "Epoch 25/80\n",
      "9139/9139 [==============================] - 9s 973us/step - loss: 0.3582 - acc: 0.8726 - val_loss: 0.4381 - val_acc: 0.8379\n",
      "Epoch 26/80\n",
      "9139/9139 [==============================] - 9s 971us/step - loss: 0.3395 - acc: 0.8799 - val_loss: 0.4985 - val_acc: 0.8132\n",
      "Epoch 27/80\n",
      "9139/9139 [==============================] - 9s 969us/step - loss: 0.3453 - acc: 0.8765 - val_loss: 0.4995 - val_acc: 0.8291\n",
      "Epoch 28/80\n",
      "9139/9139 [==============================] - 9s 972us/step - loss: 0.3400 - acc: 0.8773 - val_loss: 0.4554 - val_acc: 0.8350\n",
      "Epoch 29/80\n",
      "9139/9139 [==============================] - 9s 971us/step - loss: 0.3328 - acc: 0.8799 - val_loss: 0.4549 - val_acc: 0.8281\n",
      "Epoch 30/80\n",
      "9139/9139 [==============================] - 9s 976us/step - loss: 0.3195 - acc: 0.8881 - val_loss: 0.5107 - val_acc: 0.8103\n",
      "Epoch 31/80\n",
      "9139/9139 [==============================] - 9s 989us/step - loss: 0.3176 - acc: 0.8888 - val_loss: 0.4738 - val_acc: 0.8291\n",
      "Epoch 32/80\n",
      "9139/9139 [==============================] - 9s 994us/step - loss: 0.3055 - acc: 0.8942 - val_loss: 0.5266 - val_acc: 0.8043\n",
      "Epoch 33/80\n",
      "9139/9139 [==============================] - 9s 975us/step - loss: 0.2997 - acc: 0.8921 - val_loss: 0.5020 - val_acc: 0.8142\n",
      "Epoch 34/80\n",
      "9139/9139 [==============================] - 9s 980us/step - loss: 0.2973 - acc: 0.8956 - val_loss: 0.4730 - val_acc: 0.8419\n",
      "Epoch 35/80\n",
      "9139/9139 [==============================] - 9s 980us/step - loss: 0.2838 - acc: 0.8982 - val_loss: 0.4802 - val_acc: 0.8310\n",
      "Epoch 36/80\n",
      "9139/9139 [==============================] - 9s 975us/step - loss: 0.2802 - acc: 0.9020 - val_loss: 0.4733 - val_acc: 0.8389\n",
      "Epoch 37/80\n",
      "9139/9139 [==============================] - 9s 974us/step - loss: 0.2724 - acc: 0.9055 - val_loss: 0.4823 - val_acc: 0.8281\n",
      "Epoch 38/80\n",
      "9139/9139 [==============================] - 9s 973us/step - loss: 0.2578 - acc: 0.9104 - val_loss: 0.5251 - val_acc: 0.8291\n",
      "Epoch 39/80\n",
      "9139/9139 [==============================] - 9s 973us/step - loss: 0.2729 - acc: 0.9027 - val_loss: 0.5383 - val_acc: 0.8182\n",
      "Epoch 40/80\n",
      "9139/9139 [==============================] - 9s 972us/step - loss: 0.2509 - acc: 0.9104 - val_loss: 0.5116 - val_acc: 0.8271\n",
      "Epoch 41/80\n",
      "9139/9139 [==============================] - 9s 971us/step - loss: 0.2490 - acc: 0.9133 - val_loss: 0.5020 - val_acc: 0.8389\n",
      "Epoch 42/80\n",
      "9139/9139 [==============================] - 9s 987us/step - loss: 0.2539 - acc: 0.9129 - val_loss: 0.4943 - val_acc: 0.8439\n",
      "Epoch 43/80\n",
      "9139/9139 [==============================] - 9s 988us/step - loss: 0.2383 - acc: 0.9186 - val_loss: 0.5170 - val_acc: 0.8202\n",
      "Epoch 44/80\n",
      "9139/9139 [==============================] - 9s 980us/step - loss: 0.2397 - acc: 0.9175 - val_loss: 0.5538 - val_acc: 0.8123\n",
      "Epoch 45/80\n",
      "9139/9139 [==============================] - 9s 976us/step - loss: 0.2250 - acc: 0.9230 - val_loss: 0.5187 - val_acc: 0.8310\n",
      "1012/1012 [==============================] - 0s 385us/step\n",
      "[0.76923077 0.62162162 0.90008258 0.72794118]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "import itertools\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import f1_score\n",
    "import tools_split_90_10 as tools\n",
    "\n",
    "training_data, training_label, validation_data, validation_label, validation_cate_label = tools.get_data()\n",
    "\n",
    "kernel_size = [5]\n",
    "num_layers = [10]\n",
    "batch_size = [30]\n",
    "learning_rate = [0.0001]\n",
    "overflow_model = 0\n",
    "\n",
    "def run(bs, lr, ks, num_layer):\n",
    "    model = tools.create_model(lr, bs, ks, num_layer)\n",
    "    early_stop = EarlyStopping(patience=20)\n",
    "    history = model.fit(x = training_data, \n",
    "                        y = training_label,\n",
    "                        epochs=80,\n",
    "                        validation_data=(validation_data, validation_label),\n",
    "                        callbacks=[early_stop],\n",
    "                        batch_size=bs, \n",
    "                        verbose=1)\n",
    "    evaluation = model.evaluate(x = validation_data, y = validation_label)\n",
    "    validation_prediction = model.predict_classes(validation_data, batch_size=bs)\n",
    "    score = f1_score(validation_cate_label, validation_prediction, average=None)\n",
    "    \n",
    "    del model\n",
    "    return score\n",
    "\n",
    "## main()\n",
    "\n",
    "index=1\n",
    "for ks, num_layer, bs, lr in itertools.product(kernel_size, num_layers, batch_size, learning_rate):\n",
    "    print(\"Index \"+str(index))\n",
    "    \n",
    "    model = tools.create_model(lr, bs, ks, num_layer)\n",
    "    \n",
    "    score = run(bs, lr, ks, num_layer)\n",
    "    print(score)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
